<!DOCTYPE html>


<html lang="en">
  

    <head>
      <meta charset="utf-8" />
       
      <meta name="keywords" content="wgj&#39;s博客,大学课程知识,计算机课程知识,算法知识,实验研究,论文写作,计算机视觉,CV,CSU,xjtu" />
       
      <meta name="description" content="一名计算机专业大学生的博客，分享个人算法笔记、课程知识总结以及实验研究和论文写作" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>2022年期末总结 |  Wgj&#39;s blog</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <script src="https://cdn.staticfile.org/mermaid/8.14.0/mermaid.min.js"></script>
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    <link rel="alternate" href="/atom.xml" title="Wgj's blog" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>
  </html>
</html>


<body>
  <div id="app">
    
      <canvas class="fireworks"></canvas>
      <style>
        .fireworks {
          position: fixed;
          left: 0;
          top: 0;
          z-index: 99999;
          pointer-events: none;
        }
      </style>
      
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-University/junior/course/Scientific Computing and Mathematical Modeling/开卷宝典plus+"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  2022年期末总结
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/05/11/University/junior/course/Scientific%20Computing%20and%20Mathematical%20Modeling/%E5%BC%80%E5%8D%B7%E5%AE%9D%E5%85%B8plus+/" class="article-date">
  <time datetime="2023-05-11T02:42:01.567Z" itemprop="datePublished">2023-05-11</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%A4%A7%E5%AD%A6/">大学</a> / <a class="article-category-link" href="/categories/%E5%A4%A7%E5%AD%A6/%E5%A4%A7%E4%B8%89/">大三</a> / <a class="article-category-link" href="/categories/%E5%A4%A7%E5%AD%A6/%E5%A4%A7%E4%B8%89/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/">科学计算与数学建模</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">20.6k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">73 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1>科学计算与数学建模期末总结</h1>
<p>目录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">判断 1分*10个</span><br><span class="line">单选 2分*5个</span><br><span class="line">多选 3分*10个</span><br><span class="line">简答 10分*3个</span><br><span class="line">综合简答 1个*20分</span><br></pre></td></tr></table></figure>
<p>[TOC]</p>
<h2 id="必考">必考</h2>
<h3 id="考-cnn-通道数与filter个数相等">考.CNN.通道数与filter个数相等</h3>
<blockquote>
<p><img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20221007084324665.png" alt="image-20221007084324665"></p>
<p>新的图片的通道数 与 卷积过程中的filter个数的关系  <strong>相等</strong></p>
</blockquote>
<h3 id="考-隐空间和特征空间的关系">考.隐空间和特征空间的关系</h3>
<blockquote>
<p>在深度学习中，隐空间和特征空间是两个重要的概念，它们之间有一定的关系。</p>
<p>特征空间是指输入数据经过特征提取之后所构成的空间。在深度学习中，我们通常会将输入数据通过多层神经网络进行变换和抽象，最终得到一个更加抽象、更有意义的特征表示。这个特征表示的空间就是特征空间。在特征空间中，每个数据样本都被表示为一个向量，这个向量的每个维度代表了某个特征的值，因此特征空间中的每个维度都对应着某种意义，如像素值、颜色等。</p>
<p>隐空间是指神经网络中的隐藏层输出所构成的空间。隐藏层是神经网络中的一层，其输出是由输入数据经过一系列非线性变换和激活函数处理得到的。隐空间中的每个维度都代表了神经元的输出值，这些神经元可以认为是在对输入数据进行某种高级抽象和表示。因此，隐空间的维度往往比特征空间的维度更高，同时隐空间中的每个维度往往难以解释。</p>
<p>隐空间和特征空间之间的关系通常体现在神经网络的训练过程中。在训练过程中，神经网络通过不断地调整参数，使得隐空间中的表示可以更好地捕捉数据的特征，并能够将不同类别的数据样本分开。同时，隐空间的输出也可以被进一步处理和解释，得到更加有意义的特征表示，从而提高神经网络在各种任务中的表现。因此，隐空间和特征空间是深度学习中两个非常重要的概念，它们之间的关系对于深度学习算法的理解和优化都有着重要的意义。</p>
</blockquote>
<h3 id="考-神经网络为什么deep不fat">考.神经网络为什么Deep不Fat</h3>
<blockquote>
<p>可以使用更少的数据产生同样的效果</p>
</blockquote>
<blockquote>
<p>神经网络通常会随着深度的增加而变得更加复杂和强大，而随着网络的宽度增加而变得更加庞大和容易过拟合。这就是为什么神经网络通常被描述为“deep而不fat”，即增加深度而不是增加宽度可以更好地提高网络性能的原因。</p>
<p>一方面，增加网络的深度可以使得网络能够学习到更加抽象和高层次的特征表示，从而提高网络的表现能力。这是因为深度网络可以通过层与层之间的非线性变换来逐渐组合和学习输入数据的不同抽象特征。随着网络的深度增加，网络能够更好地理解和表示数据之间的关系，并且可以通过逐层的学习来提高整个网络的表示能力。</p>
<p>另一方面，增加网络的宽度会使得网络的参数数量增加，从而容易导致过拟合。在过拟合的情况下，神经网络在训练数据上的表现很好，但在测试数据上表现较差。这是因为过拟合的网络过于适应了训练数据的噪声和特异性，而无法泛化到新的数据上。因此，在设计神经网络时，需要权衡网络的深度和宽度，以便在提高性能的同时避免过拟合。</p>
<p>总之，增加网络的深度可以提高网络的表现能力，而增加网络的宽度则容易导致过拟合。在神经网络的设计和优化中，我们需要综合考虑这两个因素，以便得到更加高效和准确的网络结构。</p>
</blockquote>
<h3 id="考-对比常见模型的建模三部曲">考.对比常见模型的建模三部曲</h3>
<blockquote>
<p><img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20230218015553982.png" alt="image-20230218015553982"></p>
<p><img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20230218015630174.png" alt="image-20230218015630174"></p>
<p><img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20230218015655491.png" alt="image-20230218015655491"></p>
<p><img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20230218015711073.png" alt="image-20230218015711073"></p>
<p><img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20230218015719284.png" alt="image-20230218015719284"></p>
</blockquote>
<h2 id="17级-换老师-参考价值低">17级（换老师，参考价值低）</h2>
<h2 id="选择题">选择题</h2>
<h3 id="梯度下降">梯度下降</h3>
<p>神经网络中的梯度下降方法：</p>
<ol>
<li class="lvl-3">
<p>A.梯度下降方法是利用数值优化中对待优化函数求导能够获敢函数变化最快方向的信息从而逐步更新函数参数的方法</p>
</li>
<li class="lvl-3">
<p>B.在神经网络中，参数是待定的，要找到最恰当拟合输入输出数据的函数，就需要构建损失函数</p>
</li>
<li class="lvl-3">
<p>D.相比于对神经网络中每个参数直接求梯度，采用<mark>反向传播算法的效率更高</mark></p>
</li>
</ol>
<h3 id="sigmoid激活函数">sigmoid激活函数</h3>
<p>A.采用sigmoid激活函数的单个神经元本质上起到了二分类的作用——❌</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>sigmoid激活函数也称<mark>S型生长曲线</mark></p>
</li>
</ul>
<p>Sigmoid函数的特性与优缺点：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Sigmoid函数的输出范围是0到1。由于输出值限定在0到1，因此它对每个神经元的输出进行了归一化。</p>
</li>
<li class="lvl-2">
<p>用于将预测概率作为输出的模型。由于概率的取值范围是0到1，因此Sigmoid函数非常合适</p>
</li>
<li class="lvl-2">
<p>梯度平滑，避免跳跃的输出值</p>
</li>
<li class="lvl-2">
<p>函数是可微的。这意味着可以找到任意两个点的Sigmoid曲线的斜率</p>
</li>
<li class="lvl-2">
<p>明确的预测，即非常接近1或0。</p>
</li>
<li class="lvl-2">
<p>函数输出不是以0为中心的，这会降低权重更新的效率</p>
</li>
<li class="lvl-2">
<p>Sigmoid函数执行指数运算，计算机运行得较慢。</p>
</li>
</ul>
<p>关于sigmoid激活函数的相关描述：</p>
<p>B.采用sigmoid激活函数的神经网络可以看成由多个逻辑回归模型叠加而成<br>
C.神经网络的参数由所有神经元连接的权重和偏差组成<br>
D.一个结构确定的神经网络对应一组函数集合，而该神经网络的参数确定后就只对应一个函数。</p>
<h3 id="全连接前馈神经网络">全连接前馈神经网络</h3>
<ol>
<li class="lvl-3">
<p>一般由多层神经元连接而成</p>
</li>
<li class="lvl-3">
<p>每层有多个神经元</p>
</li>
<li class="lvl-3">
<p>从输入到输出各层之间的神经元连接都是沿着从输入层到输出层的方向</p>
</li>
<li class="lvl-3">
<p>两相邻层的神经元之间两两互相有连接</p>
</li>
</ol>
<h3 id="关于梯度下降和反向传播算法的正确说法">关于梯度下降和反向传播算法的正确说法</h3>
<ol>
<li class="lvl-3">
<p>反向传播算法相比于直接对每个参数求梯度，计算效率更高</p>
</li>
<li class="lvl-3">
<p>随机梯度下降运行速度要比梯度下降快</p>
</li>
<li class="lvl-3">
<p>在反向传播算法中，反向传递过程可以看成一个没有激活函数的反向的神经网络</p>
</li>
<li class="lvl-3">
<p>随机梯度下降相对于梯度下降，损失函数会呈现较强的抖动</p>
</li>
</ol>
<h3 id="keras">Keras</h3>
<ol>
<li class="lvl-3">
<p>Keras实现神经网络需要首先创建模型对象</p>
</li>
<li class="lvl-3">
<p>在Keras中通过模型对象添加一个网络层的方法是add方法</p>
</li>
<li class="lvl-3">
<p>在Keras中要进行模型训练，需要调用模型的fit方法</p>
</li>
<li class="lvl-3">
<p>在Keras中添加一个网络层可以不需要设置输入维度和输出维度</p>
</li>
</ol>
<h3 id="卷积神经网络cnn">卷积神经网络CNN</h3>
<blockquote>
<p>一种特殊的深层前馈网络</p>
</blockquote>
<ol>
<li class="lvl-3">
<p>convolution layer（卷积）</p>
<ul class="lvl-2">
<li class="lvl-5">filter：过滤器，相当于神经元，每一个filter关注的范围不同，也叫<mark>卷积核</mark></li>
<li class="lvl-5">(其中每一个filter其实就等同于是fully connect layer里面的一个neuron)</li>
<li class="lvl-5">一个filter就代表了一个channel</li>
</ul>
</li>
<li class="lvl-3">
<p>max pooling layer（池化）</p>
<ul class="lvl-2">
<li class="lvl-5">将经过卷积得到的maxtrix划分成新maxtrix并取每个划分区域的最大值</li>
<li class="lvl-5"><img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/chapter21-18.png" alt=""></li>
</ul>
</li>
<li class="lvl-3">
<p>flatten layer（）</p>
<ul class="lvl-2">
<li class="lvl-5"><mark>feature map拉直</mark>，拉直之后就可以丢到fully connected feedforward netwwork</li>
<li class="lvl-5"><img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/chapter21-22.png" alt=""></li>
</ul>
</li>
</ol>
<blockquote>
<p>假设第一层filter有2个，第二层的filter在考虑这个imput时是会考虑深度的，并不是每个channel分开考虑，而是一次考虑所有的channel。所以<mark>convolution有多少个filter，output就有多少个filter</mark>(convolution有25个filter，output就有25个filter。只不过，这25个filter都是一个立方体)</p>
</blockquote>
<h4 id="卷积-in-keras">卷积 in Keras</h4>
<p><strong>model.add(Convolution2D</strong>( <strong>25, 3, 3</strong>)</p>
<p>25代表有25个filter，3 *3代表filter是一个3 *3的matrix</p>
<p><strong>Input_shape=(28,28,1)</strong></p>
<p>假设我要做手写数字辨识，<mark>input是28 *28的image，每个pixel都是单一颜色</mark>。所以input_shape是(1,28,28)。如果是黑白图为1(blacj/white)，如果是彩色的图时为3(每个pixel用三个值来表述)。</p>
<p><strong>MaxPooling2D(( 2, 2 ))</strong></p>
<p>2,2表示把2*2的feature map里面的pixel拿出来，选择max value</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/chapter21-24.png" style="zoom:50%;" />
<blockquote>
<p>第二次的Convolution中的filter的大小是3*3但是每个filter的深度是上一次Convolution的filter数25，因此每个filter的参数个数为25 * 3 * 3 = 225</p>
</blockquote>
<h4 id="实例习题">实例习题</h4>
<p><img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20230212115701358.png" alt="image-20230212115701358"></p>
<p><img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20230212123449580.png" alt="image-20230212123449580"></p>
<h4 id="应用">应用</h4>
<ol>
<li class="lvl-3">
<p>围棋AlphaGo</p>
</li>
<li class="lvl-3">
<p>语音</p>
</li>
<li class="lvl-3">
<p>文本</p>
</li>
<li class="lvl-3">
<p>虽然文本和语音是一维的时序数据，但是可以用卷积神经网络</p>
</li>
<li class="lvl-3">
<p>类激活图(class activation map)可视化方法是指对输入图像<mark>生成类激活的热力图</mark></p>
</li>
<li class="lvl-3">
<p>卷积神经网络一定会用到池化层</p>
</li>
<li class="lvl-3">
<p>从空白输入图像开始，将梯度上升应用于已训练好的卷积神经网络输入图像的值，从而让某个过滤器的响应最大化，这样可以通过可视化的形式观察卷积神经网络学到的过滤器</p>
</li>
</ol>
<h3 id="cnn与gcn">CNN与GCN</h3>
<h6 id="比较卷积神经网络cnn和图卷积神经网络gcn的异同">比较卷积神经网络CNN和图卷积神经网络GCN的异同</h6>
<ol>
<li class="lvl-3">
<p>CNN 和GCN 都是通过对空间的卷积操作提取数据的空间相关性，但<mark>CNN只能适用于规整的网格型数据</mark>，而GCN能够适用于更具一般性的图结构数据。</p>
</li>
<li class="lvl-3">
<p>CNN 的卷积操作本质上是将矩阵转化为向量后的向量内积，而GCN 的卷积本质上是傅里叶/小波变换在图结构数据上的拓展。</p>
</li>
<li class="lvl-3">
<p>GCN 的卷积操作由<u>邻居节点消息发送、节点的消息接收、节点信息融合</u>，以及节点信息更新组成，而<mark>CNN可以看成GCN 卷积操作在网格型图上的一种特例</mark>。</p>
</li>
<li class="lvl-3">
<p>CNN 的池化操作一般是<mark>平均池化或最大池化</mark>，GCN 的池化比较复杂，涉及到图结构数据中节点到聚类中心的分配。</p>
</li>
</ol>
<h3 id="图神经网络gcn">图神经网络GCN</h3>
<p>GCN的卷积运算包含以下步骤：</p>
<ol>
<li class="lvl-3">
<p>节点消息传播</p>
</li>
<li class="lvl-3">
<p>节点消息接收</p>
</li>
<li class="lvl-3">
<p>节点信息融合</p>
</li>
</ol>
<h3 id="词嵌入模型">词嵌入模型</h3>
<p>关于词嵌入模型的正确说法：</p>
<ol>
<li class="lvl-3">
<p>在多语言嵌入模型中，来自不同语言的具有相似语义信息的词汇可以得到类似的嵌入表达</p>
</li>
<li class="lvl-3">
<p>在多领域嵌入模型中，来自不同领域（文本、图像、语音等）的具有相似语义信息的实体可以得到类似的嵌入表达</p>
</li>
<li class="lvl-3">
<p>词嵌入模型没有考虑词汇在句子中的先后关系</p>
</li>
<li class="lvl-3">
<p>英语词汇的时态关系在词嵌入模型中可以保留</p>
</li>
</ol>
<h2 id="判断题"><mark>判断题</mark></h2>
<p>1.反向传播算法由前向和向传递两个阶段构成✔️<br>
2.mini-batch相比于随机梯度下降(SGG)优势在于可以通过GPU进行并行处理✔️</p>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>是的，mini-batch相比于随机梯度下降(SGD)的一个优势是可以通过GPU进行并行处理。</p>
<p>在SGD中，每个样本都被用于更新模型参数，因此每个样本都需要进行一次前向传递和一次反向传递。这种逐个样本处理的方式不利于GPU并行计算，因为GPU在进行计算时需要同时处理多个数据。因此，SGD难以充分利用GPU的并行计算能力，导致训练速度较慢。</p>
<p>相比之下，mini-batch将一部分数据样本组成一个batch，然后用这个batch进行一次前向传递和一次反向传递，从而更新模型参数。这样做的好处是，GPU可以同时处理batch中的多个数据，从而充分利用GPU的并行计算能力，加速模型训练。</p>
<p>因此，使用mini-batch进行模型训练可以在一定程度上提高训练速度，并且更适合使用GPU进行并行计算。</p>
</li>
</ul>
</blockquote>
<p>3.由CNN构成的分类模型一般不包含全连接层❌<br>
4.相比于浅层神经网络，深层神经网络实际上利用了模块化的思想✔️<br>
5.在图像识别和语音识别中，深层神经网络模型训练后都发现越是靠近输入层的神经元学出的特征越是抽象❌<br>
6.<mark>词嵌入</mark>是一种<u>无需损失函数（？）</u>的<mark>无监督学习模型</mark>❌</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Word2Vec模型是一种无需损失函数的无监督学习模型</p>
</li>
<li class="lvl-2">
<blockquote>
<p>词嵌入是一种用于将单词转换为低维向量表示的技术。通常情况下，词嵌入是通过训练一个神经网络模型来学习单词向量的。因此，词嵌入模型可以是有监督学习模型也可以是无监督学习模型，具体取决于模型的训练方式。</p>
<p>其中一种广泛使用的无监督学习模型是Word2Vec，该模型使用了跳字模型（Skip-gram）和连续词袋模型（CBOW）来学习单词向量。这些模型的训练过程是无监督的，因为它们不需要标注的标签或者目标，只需要使用输入的文本数据就可以完成模型训练。因此，Word2Vec模型是一种无需损失函数的无监督学习模型，它通过最大化一个特定的目标函数来学习单词向量，通常是最大化文本数据中单词序列的联合概率分布。</p>
<p>然而，还有其他一些词嵌入模型，如GloVe和FastText，它们可能采用不同的训练方法或目标函数，有些可能是有监督学习模型或半监督学习模型。因此，是否需要损失函数和监督信号，以及模型是否为无监督学习模型，取决于具体的词嵌入模型。</p>
</blockquote>
</li>
</ul>
<p>7,全连接前馈神经网络DN从数据相关性角度来看，实际上是检测数据在一维空间上的全局相关性或全局模式✔️<br>
8.从数据相关性角度来看，GCN检测的是数据在离散的非欧高维空间上节点与其邻居节点空间邻域结构上的相关性✔️<br>
9.从数据相关性角度来看，RNN检测的是数据在一维时序数据上的空间相关性✔️<br>
10.从各隐藏层神经元的视野域等角度来看，CNN隐藏层每个神经元的视野域是其每个输入神经元视野域的并集✔️<br>
11.神经网络从计算上可以看成矩阵运算和非线性运算的多次叠加而组成的复合函数，且网络叠加的层次可看成复合函数的嵌套深度了✔️<br>
12.随机梯度下降运行速度要比梯度下降慢❌<br>
13.深层神经网络和浅层神经网络从对函数的表示能力角度来看是差不多的，但对于同样的机器学习任务，深层神经网络相对于浅层神经网络效率上更高✔️<br>
14,词嵌入模型中输出的即为词汇的嵌入表示✔️</p>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>词嵌入模型中输出的即为词汇的嵌入表示吗？是的，词嵌入模型的输出就是每个词汇的嵌入表示。词嵌入模型是一种将词汇映射到低维空间中的向量表示的技术，它将词汇表示为连续的低维向量，也称为嵌入向量或词嵌入（Word Embedding）。</p>
<p>在词嵌入模型中，通常使用神经网络或矩阵分解等方法来训练模型。训练过程中，模型会学习到每个词汇的嵌入向量，这些嵌入向量可以用于表示词汇的语义信息、上下文信息等，有利于词汇的文本处理和语言模型的建立等任务。</p>
<p>在自然语言处理（NLP）中，词嵌入模型已经成为了一种基本的技术，被广泛应用于各种任务中，如情感分析、机器翻译、文本分类、问答系统等。</p>
</li>
</ul>
</blockquote>
<p>15.深度自编码器的解码器和编码器必须是对称的❌<br>
16.在基于卷积的自编码器中卷积运算和反卷积运算实际上是同一种运算✔️</p>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>在基于卷积的自编码器（Convolutional Autoencoder）中，卷积运算和反卷积运算是不同的运算，它们在实现上有所不同，但是它们的目的都是提取和还原图像的特征。</p>
<p>卷积运算和反卷积运算的区别主要体现在其运算过程中卷积核的使用方式上。卷积运算通过将一个卷积核在输入图像上滑动并进行点积计算，从而提取出输入图像的特征。反卷积运算则是将卷积核在输出特征图上滑动，并通过填充（padding）和步长（stride）的设置，将输出特征图的大小还原为输入图像的大小。</p>
<p>因此，卷积运算和反卷积运算虽然实现上不同，但它们都是一种类似的局部连接和参数共享的操作。在基于卷积的自编码器中，卷积运算用于提取图像特征，反卷积运算用于通过特征图还原原始图像。为了提高自编码器的性能，通常还需要加入池化层、上采样层等其他操作，以实现更高效和更精确的特征提取和还原。</p>
</li>
</ul>
</blockquote>
<h2 id="简答题">简答题</h2>
<h3 id="深度学习的本质是什么？">深度学习的本质是什么？</h3>
<blockquote>
<p>深度学习是一种人工智能领域中的机器学习方法，其本质是通过构建深度神经网络来学习数据中的复杂模式和规律。与传统机器学习方法不同，深度学习算法不需要手动提取特征，而是通过多层神经元对数据进行逐层抽象和表示学习，从而自动发现和提取有用的特征。</p>
<p>在深度学习中，神经网络通常包括多个隐藏层，每个隐藏层都由多个神经元组成，每个神经元将上一层的输出作为输入，并根据一定的权重和偏置进行计算，最终输出到下一层。通过不断地调整网络的权重和偏置，使得网络输出的结果与真实值之间的误差最小化，从而实现模型的优化和训练。</p>
<p>深度学习的本质是利用大量的数据和计算能力，自动发现并利用数据中的模式和规律，从而实现对复杂问题的准确建模和预测。通过不断增加神经网络的深度和复杂度，深度学习已经在多个领域取得了突破性的进展，例如图像识别、语音识别、自然语言处理等。</p>
</blockquote>
<h3 id="深度学习训练阶段的三个基本步骤？">深度学习训练阶段的三个基本步骤？</h3>
<blockquote>
<p>深度学习的训练通常可以分为以下三个基本步骤：</p>
<ol>
<li class="lvl-3">正向传播（Forward Propagation）：通过将输入数据喂给神经网络，让其从第一层开始逐层向前计算，直到计算出网络的输出值，这个过程就称为正向传播。在正向传播过程中，每个神经元会根据其输入和权重计算输出，并将输出传递到下一层，最终得到神经网络的输出。</li>
<li class="lvl-3">反向传播（Backward Propagation）：反向传播是深度学习中最关键的一个步骤。在反向传播中，先计算出神经网络输出的误差，然后从输出层开始逐层向后传递，通过链式法则计算每个神经元的误差贡献，并根据误差梯度调整每个神经元的权重和偏置。</li>
<li class="lvl-3">权重更新：在反向传播过程中，计算出了每个神经元的误差贡献，但并没有立即更新权重和偏置。为了避免过拟合，通常使用随机梯度下降（Stochastic Gradient Descent, SGD）等优化算法来更新权重和偏置，使得神经网络的误差逐渐减小，最终收敛到最优解。</li>
</ol>
<p>这三个步骤通常是交替进行的，即先进行一次正向传播和反向传播来计算误差梯度，然后再根据梯度更新权重和偏置。这个过程会不断迭代，直到神经网络的误差收敛到一个满意的水平或者达到预定的迭代次数。</p>
</blockquote>
<h3 id="为什么第一个步骤-正向传播-是必要的？">为什么第一个步骤(正向传播)是必要的？</h3>
<blockquote>
<p>在深度学习中，正向传播是必要的步骤之一，因为它是神经网络中的信息传递和计算过程，是得到神经网络输出的第一步。</p>
<p>正向传播的过程可以理解为神经网络的前向运算，将输入数据从第一层输入到神经网络中，通过一系列非线性变换，逐层提取数据中的特征，最终得到神经网络的输出。在这个过程中，每个神经元都会根据其输入和权重计算输出，同时将输出传递到下一层，最终得到输出层的输出。正向传播的结果即为神经网络的预测值。</p>
<p>正向传播的结果将会被用于计算预测值与真实值之间的误差，并进一步用于反向传播更新神经网络的权重和偏置。因此，正向传播不仅是得到神经网络输出的第一步，还是训练神经网络所必须的步骤之一。</p>
<p>此外，正向传播也有助于理解神经网络中的信息流和非线性变换，有助于理解神经网络的计算过程和特征提取能力。正向传播的结果可以用于可视化神经网络的隐藏层特征，有助于理解神经网络中所学到的特征和模式。</p>
</blockquote>
<h3 id="无监督模型不需要人工标注标签-是否无法完成第二个步骤-反向传播-？为什么？">无监督模型不需要人工标注标签，是否无法完成第二个步骤(反向传播)？为什么？</h3>
<blockquote>
<p>无监督学习模型也需要进行反向传播，但是与有监督学习不同，它不需要标签作为目标输出，而是通过学习数据的内在结构来调整神经网络的权重。</p>
<p>在无监督学习中，通常会使用一些自编码器（autoencoder）等无监督学习模型，通过自编码器将输入数据压缩成低维的特征向量，然后再将特征向量解码为与输入数据相同的维度。在训练过程中，无监督学习模型需要最小化重构误差，即输入数据与解码后的数据之间的差异。</p>
<p>在反向传播中，无监督学习模型会计算重构误差对于神经网络参数（包括权重和偏置）的梯度，并根据梯度调整网络参数，从而使得神经网络的重构误差逐渐减小。这个过程与有监督学习中的反向传播类似，但是无监督学习模型的反向传播不需要使用标签来计算误差。</p>
<p>需要注意的是，无监督学习的反向传播过程中并不会计算输出与目标之间的误差，而是使用一些不同的损失函数来衡量模型的性能，如重构误差、对比损失等。因此，虽然无监督学习不需要标签来进行训练，但它仍然需要进行反向传播来更新神经网络的权重和偏置。</p>
</blockquote>
<h3 id="第三个步骤-权重更新-所用的主要算法的基本原理？">第三个步骤(权重更新)所用的主要算法的基本原理？</h3>
<blockquote>
<p>第三个步骤中使用的主要算法是随机梯度下降（Stochastic Gradient Descent，SGD），它是深度学习中最基本和最常用的优化算法之一。</p>
<p>SGD的基本原理是根据损失函数的梯度信息来调整神经网络的权重和偏置，从而使得损失函数最小化。在每一轮训练中，SGD从训练集中随机选择一小批数据（称为mini-batch），计算这些数据的损失函数关于神经网络参数的梯度，然后使用梯度来更新神经网络参数，从而使得损失函数逐渐减小。</p>
<p>SGD的更新公式如下：</p>
<p>W = W - learning_rate * dW</p>
<p>其中，W表示神经网络的权重矩阵，dW表示损失函数关于权重矩阵的梯度，learning_rate表示学习率，它控制着每次参数更新的大小。</p>
<p>SGD有很多变体，如动量（Momentum）、AdaGrad、RMSProp、Adam等，它们都是在SGD的基础上做出的改进，用于加快模型训练、提高模型性能等。其中，动量算法（Momentum）通过加入一个动量项来平滑梯度下降的过程，加快收敛速度；AdaGrad算法可以自适应地调整学习率，从而更好地适应不同的参数；RMSProp算法通过对梯度进行平均来调整学习率，可以减少梯度的方差，从而更加稳定；Adam算法则结合了动量和自适应学习率的思想，具有更好的性能和收敛速度。</p>
<p>总之，SGD是深度学习中非常重要的优化算法，它通过使用梯度信息来调整神经网络的参数，使得损失函数最小化，从而实现对神经网络的训练和优化。同时，SGD的一些改进算法也可以帮助深度学习模型更快地收敛、更好地适应不同的数据分布和损失函数形式。</p>
</blockquote>
<h3 id="cnn图像识别所考虑的三个准则分别是？">CNN图像识别所考虑的三个准则分别是？</h3>
<blockquote>
<p>1、局部性准则</p>
<p>2、参数共享准则</p>
<p>3、子采样准则</p>
</blockquote>
<h3 id="三个准则分别靠cnn的哪些网络层所实现的？">三个准则分别靠CNN的哪些网络层所实现的？</h3>
<blockquote>
<p>在CNN中，三个准则通常通过不同的网络层来实现：</p>
<ol>
<li class="lvl-3">局部性准则 - 卷积层</li>
<li class="lvl-3">参数共享准则 -  卷积层</li>
<li class="lvl-3">子采样准则 - 池化层</li>
</ol>
</blockquote>
<h3 id="第2问中的各个网络层所起到的作用分别是什么？">第2问中的各个网络层所起到的作用分别是什么？</h3>
<blockquote>
<ol>
<li class="lvl-3">
<p>卷积层 (Convolutional Layers)：卷积层是CNN中最重要的层之一，它通过卷积运算来提取图像的特征。卷积层通常位于网络的前几层，它们可以检测图像中的低级特征，例如边缘、角、颜色等等。</p>
</li>
<li class="lvl-3">
<p>池化层 (Pooling Layers)：池化层通常紧随卷积层之后，用于降低特征图的维度和参数数量，同时可以帮助网络对图像的平移、缩放等变换具有一定的不变性。池化层通常使用最大池化或平均池化来实现。</p>
</li>
<li class="lvl-3">
<p>全连接层 (Fully Connected Layers)：全连接层通常位于网络的最后一层，用于将特征图映射到类别标签上。全连接层中的每个神经元都与前一层的所有神经元相连，每个输出神经元对应一个类别标签。全连接层通常使用softmax激活函数来计算每个类别的概率分布。</p>
</li>
</ol>
</blockquote>
<h3 id="keras程序理解">Keras程序理解</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>Keras实现CNN</p>
</li>
</ul>
<h4 id="使用mnist数据集训练了一个简单的cnn模型">使用MNIST数据集训练了一个简单的CNN模型</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入Keras和一些其他必要的库</span></span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D, Flatten, Dense</span><br><span class="line"><span class="comment"># 导入数据集</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()</span><br><span class="line"><span class="comment"># 将数据集reshape成4D张量</span></span><br><span class="line">x_train = x_train.reshape((x_train.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">x_test = x_test.reshape((x_test.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 数据归一化</span></span><br><span class="line">x_train = x_train / <span class="number">255.0</span></span><br><span class="line">x_test = x_test / <span class="number">255.0</span></span><br><span class="line"><span class="comment"># 将标签one-hot编码</span></span><br><span class="line">y_train = keras.utils.to_categorical(y_train)</span><br><span class="line">y_test = keras.utils.to_categorical(y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型:</span></span><br><span class="line"><span class="comment"># 首先定义了一个Sequential模型，然后依次添加了卷积层Conv2D和池化层MaxPooling2D，最后是全连接层Dense</span></span><br><span class="line">model = Sequential() <span class="comment"># 首先定义了一个Sequential模型</span></span><br><span class="line"><span class="comment"># 对于Conv2D和MaxPooling2D，</span></span><br><span class="line"><span class="comment"># 第一个参数表示卷积核（或池化窗口）的数量，</span></span><br><span class="line"><span class="comment"># 第二个参数表示卷积核的大小。</span></span><br><span class="line">model.add(Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))<span class="comment"># 序列模型加入32个*3*3大小的卷积核的卷积层（输入的形状28x28的灰度图像。在后续层中，输入形状会自动推断。激活函数使用ReLU）</span></span><br><span class="line">model.add(MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))<span class="comment"># 序列模型加入一个池化窗口大小2*2的池化层</span></span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))<span class="comment"># 序列模型加入64个*3*3大小的卷积核的卷积层（激活函数使用ReLU）</span></span><br><span class="line">model.add(MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))<span class="comment"># 序列模型加入一个池化窗口大小2*2的池化层</span></span><br><span class="line">model.add(Flatten())<span class="comment"># 把多维的输入一维化，用在从卷积层到全连接层的过渡</span></span><br><span class="line"><span class="comment"># 在全连接层中，我们添加了两个Dense层。</span></span><br><span class="line">model.add(Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))<span class="comment"># 第一个Dense层有64个神经元，使用ReLU激活函数；</span></span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))<span class="comment"># 第二个Dense层有10个神经元，使用softmax激活函数，表示输出10个类别的概率。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])<span class="comment"># 使用adam优化器、交叉熵损失函数和准确率作为评估指标</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>, validation_data=(x_test, y_test))<span class="comment">#使用训练集x_train和y_train来训练模型，指定了10个epoch，每个batch大小为32。同时，我们还使用了测试集x_test和y_test来验证模型的性能。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用测试集评估模型</span></span><br><span class="line">test_loss, test_acc = model.evaluate(x_test, y_test)<span class="comment"># 使用测试集x_test和y_test来评估模型的性能，并输出测试集的准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, test_acc)</span><br></pre></td></tr></table></figure>
<h4 id="真题-用卷积神经网络进行mnist手写数字识别">真题.用卷积神经网络进行MNIST手写数字识别</h4>
<p><img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20230219211742477.png" alt="image-20230219211742477"></p>
<p><img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20230219211759114.png" alt="image-20230219211759114"></p>
<p>其它基本与上面demo一致</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(train_images,train_labels).(test_images.test_labels)=mnist.load_data() <span class="comment"># 加载mnist数据集</span></span><br><span class="line">train_images = train_images.reshape((<span class="number">60000.28</span><span class="number">.28</span><span class="number">.1</span>)) <span class="comment"># # 将数据集reshape成4D张量：6万张训练图片，数据维度转化，增加了通道维度</span></span><br><span class="line">train_images = train_images.astype(<span class="string">&#x27;float32&#x27;</span>)/<span class="number">255</span> <span class="comment"># 归一化：将像素的值标准化至0到1的区间内。</span></span><br><span class="line"></span><br><span class="line">train_labels = to_categorical(train_labels) <span class="comment"># 将标签one-hot编码：将类别向量转换为二进制(只有0和1)的矩阵类型表示</span></span><br></pre></td></tr></table></figure>
<ul class="lvl-0">
<li class="lvl-2">
<p>Keras实现神经网络</p>
</li>
</ul>
<h4 id="用神经网络实现手写体数字识别">用神经网络实现手写体数字识别</h4>
<p>书37页</p>
<h3 id="深度学习中单个神经元与线性回归-逻辑回归-分类问题之间的关系？">深度学习中单个神经元与线性回归，逻辑回归，分类问题之间的关系？</h3>
<blockquote>
<p>单个神经元是深度学习的基本构建块之一，通常用于解决分类问题。在深度学习中，单个神经元通常包括输入、权重、偏差和激活函数。单个神经元将输入值加权求和，加上偏差，然后将该总和传递给激活函数，以产生输出。</p>
<p>线性回归和逻辑回归也是解决分类问题的基本算法之一。在线性回归中，我们试图找到一个最适合数据的线性函数，该函数可以将输入变量映射到连续的输出变量。而在逻辑回归中，我们试图找到一个最适合数据的Sigmoid函数，该函数可以将输入变量映射到一个二元输出变量（0或1）。</p>
<p>从形式上看，单个神经元的计算过程与线性回归和逻辑回归非常相似。事实上，可以将线性回归和逻辑回归看作是一种特殊类型的神经网络，其中只有一个神经元。通过组合多个这样的神经元，我们可以构建更复杂的神经网络，以解决更复杂的分类问题。</p>
</blockquote>
<h3 id="独热编码的概念？">独热编码的概念？</h3>
<blockquote>
<p>独热编码（One-Hot Encoding）是一种将分类数据转换为计算机可处理格式的编码方式。它将每个分类值映射到一个整数值，然后将这些整数值用一个二进制向量表示，其中只有一个位置是 1，其余位置都是 0。这个唯一的位置对应于整数值，表示该分类值的存在。</p>
<p>例如，假设有一个颜色变量，可能的取值为 “red”、“green” 和 “blue”。将这些取值转换为独热编码将得到：</p>
<table>
<thead>
<tr>
<th>颜色</th>
<th>red</th>
<th>green</th>
<th>blue</th>
</tr>
</thead>
<tbody>
<tr>
<td>red</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>green</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>blue</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>通过使用独热编码，可以将分类变量转换为计算机可以处理的形式，并可以在机器学习模型中使用这些编码变量。</p>
</blockquote>
<h3 id="词嵌入模型的工作原理？">词嵌入模型的工作原理？</h3>
<blockquote>
<p>词嵌入模型是一种将自然语言文本中的单词映射到实数值向量的技术。它能够捕捉单词之间的语义和上下文关系，并为自然语言处理（NLP）任务提供了有用的表示。</p>
<p>词嵌入模型的工作原理可以分为以下几个步骤：</p>
<ol>
<li class="lvl-3">
<p>数据预处理：首先需要对文本进行预处理，例如分词、去除停用词等。</p>
</li>
<li class="lvl-3">
<p>建立词汇表：将预处理后的文本中所有的单词建立一个词汇表，每个单词对应一个唯一的整数标识。</p>
</li>
<li class="lvl-3">
<p>训练模型：通过对大量的语料库进行训练，词嵌入模型可以学习到每个单词的向量表示。其中，最常用的词嵌入模型是 Word2Vec 和 GloVe。</p>
</li>
<li class="lvl-3">
<p>应用模型：训练好的模型可以用于不同的NLP任务，例如情感分析、文本分类、命名实体识别等。</p>
</li>
</ol>
<p>Word2Vec 模型使用两种不同的架构进行训练，分别为连续词袋模型（CBOW）和Skip-Gram模型。CBOW模型根据上下文单词来预测当前单词，而Skip-Gram模型则根据当前单词来预测上下文单词。GloVe模型则是基于全局统计信息进行训练，将单词之间的共现信息转换为向量表示。</p>
<p>总之，词嵌入模型利用机器学习算法将自然语言中的单词映射到低维向量空间中，从而能够有效地捕捉单词之间的语义和上下文关系。</p>
</blockquote>
<h3 id="词嵌入模型中为什么语义相近的词汇通常有相似的嵌入表示？">词嵌入模型中为什么语义相近的词汇通常有相似的嵌入表示？</h3>
<blockquote>
<p>在词嵌入模型中，语义相近的词汇通常会被赋予相似的嵌入表示，这是因为词嵌入模型是基于语料库中的上下文信息进行训练的，而语义相近的单词通常会在上下文中出现在类似的语境中。</p>
<p>例如，在一个包含 “apple”、“orange” 和 “banana” 的语料库中，这些单词可能会在 “水果” 的上下文中出现，因此它们会被认为在语义上相近。如果我们使用 Word2Vec 模型进行训练，它会学习到将这些单词映射到低维向量空间中的向量表示。由于它们在上下文中的共现信息相似，所以它们在向量空间中的距离也会比较接近。</p>
<p>另外，词嵌入模型还可以通过使用负采样（Negative Sampling）等技术来调整单词之间的相似度。通过在训练过程中引入噪声单词，并使嵌入向量在某些方向上更多地适应噪声单词，我们可以更好地调整词向量的相似度，并更准确地捕捉单词之间的语义关系。</p>
<p>因此，词嵌入模型之所以能够为语义相近的单词学习到相似的向量表示，是因为它利用了语料库中单词的上下文信息，并通过训练过程中的优化算法来调整单词之间的相似度。</p>
</blockquote>
<h3 id="从网络结构-输入数据形式和数据之间的关联-提取数据特征的相关性-各隐藏层神经-dnn-cnn-rnn-gcn异同？">从网络结构，输入数据形式和数据之间的关联，提取数据特征的相关性，各隐藏层神经、DNN，CNN，RNN，GCN异同？</h3>
<p>DNN(深度神经网络)，CNN(卷积神经网络)，RNN(循环神经网络)，GCN(图卷积神经网络)</p>
<blockquote>
<p>神经网络是一种用于机器学习和深度学习的模型，它由输入层、隐藏层和输出层组成。隐藏层是神经网络的核心，它可以提取数据的特征并将其转化为更高层次的表示。神经网络的结构可以根据不同的任务和数据类型进行优化。</p>
<p>以下是一些不同类型的神经网络以及它们之间的区别：</p>
<ol>
<li class="lvl-3">
<p>DNN（深度神经网络）：DNN由多个隐藏层组成，每个隐藏层都包含多个神经元，每个神经元都与上一层的所有神经元相连。DNN通常用于处理结构化数据，如数字或文本，其输入数据形式通常是向量或矩阵。</p>
</li>
<li class="lvl-3">
<p>CNN（卷积神经网络）：CNN通过使用卷积层和池化层提取输入数据的特征，以适应图像、视频和语音等非结构化数据的处理。卷积层会对输入数据进行局部卷积操作，以提取输入数据的局部特征，而池化层则会对卷积层的输出进行降采样，以减少数据的维度。CNN的输入数据形式通常是图像、音频或视频等多维数组。</p>
</li>
<li class="lvl-3">
<p>RNN（循环神经网络）：RNN的隐藏层神经元之间形成循环结构，使得前一时刻的输出可以作为当前时刻的输入。这使得RNN适用于处理序列数据，如时间序列、自然语言和音频数据。RNN通过使用门控单元（如LSTM或GRU）来解决长期依赖问题，以避免梯度消失或梯度爆炸的问题。</p>
</li>
<li class="lvl-3">
<p>GCN（图卷积网络）：GCN是一种用于处理图数据的神经网络，其输入数据通常是节点和边的列表。GCN通过使用卷积层来学习节点的嵌入表示，以提取图的结构信息和节点之间的关系。GCN还使用池化层来减少节点的数量，以适应更大的图。</p>
</li>
</ol>
<p>总的来说，不同类型的神经网络适用于不同类型的数据和任务，它们通过不同的方式提取和处理数据的特征，并将其转化为更高层次的表示。</p>
</blockquote>
<h3 id="单个神经元作用小-多个大？">单个神经元作用小，多个大？</h3>
<blockquote>
<p>单个神经元作用小的原因在于它只能对输入数据做出非常简单的线性变换和激活操作，很难对复杂的模式和特征进行捕捉。而多个神经元可以通过组合和并行处理不同的输入特征，提取更复杂的特征表示，从而更好地完成任务。</p>
<p>具体来说，多个神经元的组合可以实现更复杂的非线性函数，能够学习更丰富的特征表示。同时，隐藏层的深度越多，神经元的数量也越多，神经网络的表达能力也会更加强大。这意味着神经网络可以对数据进行更深入的学习和建模，从而更准确地预测结果。</p>
<p>此外，多个神经元还可以通过并行处理输入数据的不同方面来提高效率和准确性。比如，在图像分类任务中，一个神经元可能专门处理边缘特征，另一个神经元则处理颜色和纹理特征，多个神经元的组合可以更好地捕捉图像中的多个方面特征。</p>
<p>因此，多个神经元通常可以提高神经网络的表达能力和性能，使其更好地适应复杂的数据和任务。</p>
</blockquote>
<h3 id="现有深度学习模型的局限性？">现有深度学习模型的局限性？</h3>
<blockquote>
<p>深度学习模型已经在许多领域中取得了显著的进展，如图像识别、自然语言处理、语音识别等。然而，深度学习模型仍然存在一些局限性：</p>
<ol>
<li class="lvl-3">数据需求量大：深度学习模型需要大量的标注数据来进行训练，而这些数据往往需要人工标注，成本较高。缺乏足够的数据可能会导致过拟合，从而影响模型的性能。</li>
<li class="lvl-3">模型复杂性高：深度学习模型通常由多个层和大量的参数组成，需要消耗大量的计算资源和时间进行训练。此外，模型结构的设计和调整也需要高度的专业知识和经验。</li>
<li class="lvl-3">可解释性差：深度学习模型通常是黑盒模型，其决策过程和内部表示难以理解和解释。这使得深度学习模型在某些需要解释和可靠性保证的场景中受到限制，如医疗诊断和司法决策等。</li>
<li class="lvl-3">对抗攻击易受影响：深度学习模型容易受到对抗性样本的攻击，即对模型输入进行微小的修改，可以使模型做出错误的决策。这对于安全性和可靠性的场景来说是一项重要的挑战。</li>
<li class="lvl-3">数据分布偏差：深度学习模型在训练过程中可能会受到数据分布偏差的影响，即训练集与实际应用场景的数据分布不一致，从而影响模型的泛化能力。</li>
<li class="lvl-3">缺乏因果关系：深度学习模型通常只能捕捉数据之间的相关性，而难以建立因果关系。这意味着深度学习模型可能无法解释事件之间的因果关系，从而在一些决策和预测场景中受到限制。</li>
</ol>
<p>以上是深度学习模型目前存在的一些局限性，这些局限性需要通过不断的研究和技术创新来解决，以进一步提高深度学习模型的性能和可靠性。</p>
</blockquote>
<h3 id="分别通过dnn-cnn-gcn刻画城市各个路段的车速的空间相关性？">分别通过DNN，CNN，GCN刻画城市各个路段的车速的空间相关性？</h3>
<blockquote>
<p>针对城市路段的车速数据，可以使用不同的神经网络架构来刻画其空间相关性，包括深度神经网络（DNN），卷积神经网络（CNN）和图卷积网络（GCN）。以下是每种神经网络架构的示例用法：</p>
<p>1、DNN（深度神经网络）：</p>
<p>深度神经网络是一种前馈神经网络，其目的是从输入数据中学习一个映射函数，以预测目标变量。在此场景下，输入是车速数据，目标变量是城市各个路段的车速空间相关性。具体来说，可以使用多层感知器（MLP）模型，该模型具有多个隐藏层，并使用非线性激活函数来建模输入数据中的复杂关系。通过使用DNN，可以学习路段之间的非线性依赖性，并预测城市中各个路段之间的车速相关性。</p>
<p>2、CNN（卷积神经网络）：</p>
<p>卷积神经网络是一种专门用于处理具有网格结构输入数据的神经网络，如图像和时间序列数据。在城市路段的车速数据中，可以将每个路段的车速数据视为时间序列数据，并使用卷积神经网络来刻画空间相关性。在这种情况下，CNN可以看作是一种序列模型，其中每个路段的车速数据作为序列中的一个时间步骤。通过使用CNN，可以学习城市中不同路段之间的时空相关性，并预测路段之间的车速相关性。</p>
<p>3、GCN（图卷积神经网络）：</p>
<p>图卷积神经网络是一种专门用于处理图数据的神经网络，其中节点之间的连接形成了一个图结构。在城市路段的车速数据中，可以将每个路段视为图中的一个节点，并使用车速数据中的空间关系来建立图的连接。使用GCN，可以学习城市中不同路段之间的空间相关性，并预测路段之间的车速相关性。</p>
</blockquote>
<h1>科学计算与数学建模</h1>
<h4 id="课程学习内容：">课程学习内容：</h4>
<p>机器学习基础、线性回归、偏差和方差、梯度下降、分类、逻辑回归</p>
<p>深度学习概述、反向传播和<strong>Keras</strong>编程、卷积神经网络CNN</p>
<p>为何需要深层次的网络、自编码器、词嵌入模型、循环神经网络</p>
<p><strong>Meta Learning</strong>、<strong>AE attack</strong></p>
<h2 id="一-线性回归">一、线性回归</h2>
<p>线性模型假设 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>b</mi><mo>+</mo><mi>w</mi><mo separator="true">⋅</mo><msub><mi>x</mi><mrow><mi>c</mi><mi>p</mi></mrow></msub></mrow><annotation encoding="application/x-tex">y = b + w·x_{cp}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7306em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> ，所以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span> <mark>可以猜测很多模型（得到线性模型函数集）</mark>：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub><mo>:</mo><mi>y</mi><mo>=</mo><mn>10.0</mn><mo>+</mo><mn>9.0</mn><mo separator="true">⋅</mo><msub><mi>x</mi><mrow><mi>c</mi><mi>p</mi></mrow></msub><mspace linebreak="newline"></mspace><msub><mi>f</mi><mn>2</mn></msub><mo>:</mo><mi>y</mi><mo>=</mo><mn>9.8</mn><mo>+</mo><mn>9.2</mn><mo separator="true">⋅</mo><msub><mi>x</mi><mrow><mi>c</mi><mi>p</mi></mrow></msub><mspace linebreak="newline"></mspace><msub><mi>f</mi><mn>3</mn></msub><mo>:</mo><mi>y</mi><mo>=</mo><mo>−</mo><mn>0.8</mn><mo>−</mo><mn>1.2</mn><mo separator="true">⋅</mo><msub><mi>x</mi><mrow><mi>c</mi><mi>p</mi></mrow></msub><mspace linebreak="newline"></mspace><mo separator="true">⋅</mo><mo separator="true">⋅</mo><mo separator="true">⋅</mo></mrow><annotation encoding="application/x-tex">f_1: y = 10.0 + 9.0·x_{cp} \\
f_2: y = 9.8 + 9.2·x_{cp} \\
f_3: y = - 0.8 - 1.2·x_{cp} \\
···
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">10.0</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9305em;vertical-align:-0.2861em;"></span><span class="mord">9.0</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">9.8</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9305em;vertical-align:-0.2861em;"></span><span class="mord">9.2</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">−</span><span class="mord">0.8</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9305em;vertical-align:-0.2861em;"></span><span class="mord">1.2</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.4445em;"></span><span class="mpunct">⋅⋅⋅</span></span></span></span></span></p>
<p><strong>问题转换为：从猜测的函数集中找到合适的y=b+w·<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>c</mi><mi>p</mi></mrow></msub></mrow><annotation encoding="application/x-tex"> x_{cp}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>函数刻画以上所有数据集的模型</strong></p>
<p>如何找到最合适的函数</p>
<h3 id="引入-损失函数">引入_损失函数</h3>
<blockquote>
<p>损失函数**L(f)<strong>是函数</strong>f=b+w·<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>c</mi><mi>p</mi></mrow></msub></mrow><annotation encoding="application/x-tex"> x_{cp}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>**的函数</p>
<p>input:a function	output:how bad it is</p>
<p>常见L(f)的定义方法——<strong>估计误差</strong></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="normal">L</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi mathvariant="normal">L</mi><mo stretchy="false">(</mo><mi>w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msup><mrow><mo fence="true">(</mo><msup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>n</mi></msup><mo>−</mo><mrow><mo fence="true">(</mo><mi>b</mi><mo>+</mo><mi>w</mi><mo>⋅</mo><msubsup><mi>x</mi><mrow><mi>c</mi><mi>p</mi></mrow><mi>n</mi></msubsup><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mn>2</mn></msup></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\mathrm{L}(f) &amp;=\mathrm{L}(w, b) \\
&amp;=\sum_{n=1}^{N}\left(\hat{y}^{n}-\left(b+w \cdot x_{c p}^{n}\right)\right)^{2}
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.8954em;vertical-align:-2.1977em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.6977em;"><span style="top:-5.6861em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord mathrm">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mclose">)</span></span></span><span style="top:-3.1977em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.1977em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.6977em;"><span style="top:-5.6861em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathrm">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span></span></span><span style="top:-3.1977em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7144em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">p</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.054em;"><span style="top:-3.3029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.1977em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul class="lvl-1">
<li class="lvl-2">
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">\hat{y}^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>真正数值，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>b</mi><mo>+</mo><mi>w</mi><mo>⋅</mo><msubsup><mi>x</mi><mrow><mi>c</mi><mi>p</mi></mrow><mi>n</mi></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(b+w \cdot x_{c p}^{n})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4445em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1331em;vertical-align:-0.3831em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">p</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>为当前函数的预测数值</p>
</li>
<li class="lvl-2">
<p>将每一只宝可梦（真正数值-预测数值）的平方和就是估测误差</p>
</li>
</ul>
</blockquote>
<p><strong>问题转换为：从猜测的函数集中找到损失函数L(f)最小的函数</strong></p>
<p>求出所有可能的模型的损失函数太费时</p>
<h3 id="引入-梯度下降">引入_梯度下降</h3>
<blockquote>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mo lspace="0em" rspace="0em">∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><msub><mrow><mi>min</mi><mo>⁡</mo></mrow><mi>f</mi></msub><mi>L</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f^{*}=\arg \min _{f} L(f)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mclose">)</span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msup><mi>w</mi><mo lspace="0em" rspace="0em">∗</mo></msup><mo separator="true">,</mo><msup><mi>b</mi><mo lspace="0em" rspace="0em">∗</mo></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mrow><mi>w</mi><mo separator="true">,</mo><mi>b</mi></mrow></munder><mi>L</mi><mo stretchy="false">(</mo><mi>w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mrow><mi>w</mi><mo separator="true">,</mo><mi>b</mi></mrow></munder><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mn>10</mn></munderover><msup><mrow><mo fence="true">(</mo><msup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>n</mi></msup><mo>−</mo><mrow><mo fence="true">(</mo><mi>b</mi><mo>+</mo><mi>w</mi><mo>⋅</mo><msubsup><mi>x</mi><mrow><mi>c</mi><mi>p</mi></mrow><mi>n</mi></msubsup><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mn>2</mn></msup></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
w^{*}, b^{*} &amp;=\arg \min _{w, b} L(w, b) \\
&amp;=\arg \min _{w, b} \sum_{n=1}^{10}\left(\hat{y}^{n}-\left(b+w \cdot x_{c p}^{n}\right)\right)^{2}
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:5.3964em;vertical-align:-2.4482em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.9482em;"><span style="top:-5.9093em;"><span class="pstrut" style="height:3.8011em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span></span></span><span style="top:-2.92em;"><span class="pstrut" style="height:3.8011em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.4482em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.9482em;"><span style="top:-5.9093em;"><span class="pstrut" style="height:3.8011em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.3479em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">b</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8882em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span></span></span><span style="top:-2.92em;"><span class="pstrut" style="height:3.8011em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.3479em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">b</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8882em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8011em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7144em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">p</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.054em;"><span style="top:-3.3029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.4482em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>表示当函数L(f)取<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo><msup><mi>f</mi><mo lspace="0em" rspace="0em">∗</mo></msup></mrow><annotation encoding="application/x-tex">f=f^{*}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span>的时候，得到L(f)取值范围的最小值</p>
</blockquote>
<p><strong>问题转换为：求<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>w</mi><mo lspace="0em" rspace="0em">∗</mo></msup><mo separator="true">,</mo><msup><mi>b</mi><mo lspace="0em" rspace="0em">∗</mo></msup></mrow><annotation encoding="application/x-tex">w^{*}, b^{*}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span>使得L(f)取值范围的最小值</strong></p>
<p>先从最简单的只有一个参数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span>入手，定义<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>w</mi><mo>∗</mo></msup><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mtext> </mtext><mi><munder><mo><mi mathvariant="normal"><mi>min</mi><mo>⁡</mo></mi><mo>⁡</mo></mo><mi>x</mi></munder></mi><mi>L</mi><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">w^* = arg\ \underset{x}{\operatorname{\min}} L(w)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.45em;vertical-align:-0.7em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mspace"> </span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.4em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop"><span class="mop"><span class="mop">min</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mclose">)</span></span></span></span></p>
<p><strong>问题转换为：求<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>w</mi><mo lspace="0em" rspace="0em">∗</mo></msup><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">w^{*}, </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8831em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span>使得L(w)取值范围的最小值</strong></p>
<blockquote>
<p>引入一个概念 学习率 ：移动的步长</p>
<img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20221005230548704.png" alt="image-20221005230548704" style="zoom: 33%;" />
<ul class="lvl-1">
<li class="lvl-2">
<p>步骤1：随机选取一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>w</mi><mn>0</mn></msup></mrow><annotation encoding="application/x-tex">w^0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></p>
</li>
<li class="lvl-2">
<p>步骤2：计算微分，也就是当前的斜率，根据斜率来判定移动的方向</p>
<ul class="lvl-3">
<li class="lvl-4">小于0向右移动（<strong>减少</strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span>）</li>
<li class="lvl-4">大于0向左移动（<strong>增加</strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span>）</li>
</ul>
</li>
<li class="lvl-2">
<p>步骤3：根据学习率移动</p>
</li>
<li class="lvl-2">
<p>重复步骤2和步骤3，直到找到最低点</p>
</li>
</ul>
<p>以上步骤能找到极小点，而在回归中极小点就是唯一最小点（No local optimal，疑问🤔️后面会讲）</p>
<p><mark>计算</mark></p>
<p><strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mfrac><mrow><mi>d</mi><mi>L</mi></mrow><mrow><mi>d</mi><mi>w</mi></mrow></mfrac><mo fence="true">∣</mo></mrow><mrow><mi>w</mi><mo>=</mo><msup><mi>w</mi><mn>0</mn></msup></mrow></msub></mrow><annotation encoding="application/x-tex">\left.\frac{d L}{d w}\right|_{w=w^{0}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2798em;vertical-align:-0.3997em;"></span><span class="minner"><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-2.85em;"><span class="pstrut" style="height:3.2em;"></span><span style="width:0.333em;height:1.200em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.333em' height='1.200em' viewBox='0 0 333 1200'><path d='M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1227em;"><span style="top:-2.3003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3997em;"><span></span></span></span></span></span></span></span></span></span></strong></p>
<p><strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>w</mi><mn>1</mn></msup><mo>←</mo><msup><mi>w</mi><mn>0</mn></msup><mo>−</mo><msub><mrow><mi>η</mi><mfrac><mrow><mi>d</mi><mi>L</mi></mrow><mrow><mi>d</mi><mi>w</mi></mrow></mfrac><mo fence="true">∣</mo></mrow><mrow><mi>w</mi><mo>=</mo><msup><mi>w</mi><mn>0</mn></msup></mrow></msub></mrow><annotation encoding="application/x-tex">w^{1} \leftarrow w^{0}-\left.\eta \frac{d L}{d w}\right|_{w=w^{0}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2798em;vertical-align:-0.3997em;"></span><span class="minner"><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-2.85em;"><span class="pstrut" style="height:3.2em;"></span><span style="width:0.333em;height:1.200em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.333em' height='1.200em' viewBox='0 0 333 1200'><path d='M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1227em;"><span style="top:-2.3003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3997em;"><span></span></span></span></span></span></span></span></span></span></strong></p>
</blockquote>
<p>又当同时考虑两个参数的时候</p>
<blockquote>
<p><mark>计算</mark></p>
<p><strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>w</mi></mrow></mfrac><mo fence="true">∣</mo></mrow><mrow><mi>w</mi><mo>=</mo><msup><mi>w</mi><mn>0</mn></msup><mo separator="true">,</mo><mi>b</mi><mo>=</mo><msup><mi>b</mi><mn>0</mn></msup></mrow></msub><mo separator="true">,</mo><msub><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>b</mi></mrow></mfrac><mo fence="true">∣</mo></mrow><mrow><mi>w</mi><mo>=</mo><msup><mi>w</mi><mn>0</mn></msup></mrow></msub><mo separator="true">,</mo><mi>b</mi><mo>=</mo><msup><mi>b</mi><mn>0</mn></msup></mrow><annotation encoding="application/x-tex">\left.\frac{\partial L}{\partial w}\right|_{w=w^{0}, b=b^{0}},\left.\frac{\partial L}{\partial b}\right|_{w=w^{0}}, b=b^{0}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4159em;vertical-align:-0.5358em;"></span><span class="minner"><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-2.85em;"><span class="pstrut" style="height:3.2em;"></span><span style="width:0.333em;height:1.200em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.333em' height='1.200em' viewBox='0 0 333 1200'><path d='M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1227em;"><span style="top:-2.3003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">b</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">b</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-2.85em;"><span class="pstrut" style="height:3.2em;"></span><span style="width:0.333em;height:1.200em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.333em' height='1.200em' viewBox='0 0 333 1200'><path d='M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1227em;"><span style="top:-2.3003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></span></strong></p>
<p><strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>w</mi><mn>1</mn></msup><mo>←</mo><msup><mi>w</mi><mn>0</mn></msup><mo>−</mo><msub><mrow><mi>η</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>w</mi></mrow></mfrac><mo fence="true">∣</mo></mrow><mrow><mi>w</mi><mo>=</mo><msup><mi>w</mi><mn>0</mn></msup><mo separator="true">,</mo><mi>b</mi><mo>=</mo><msup><mi>b</mi><mn>0</mn></msup></mrow></msub><mspace width="1em"/><msup><mi>b</mi><mn>1</mn></msup><mo>←</mo><msup><mi>b</mi><mn>0</mn></msup><mo>−</mo><msub><mrow><mi>η</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>b</mi></mrow></mfrac><mo fence="true">∣</mo></mrow><mrow><mi>w</mi><mo>=</mo><msup><mi>w</mi><mn>0</mn></msup><mo separator="true">,</mo><mi>b</mi><mo>=</mo><msup><mi>b</mi><mn>0</mn></msup></mrow></msub></mrow><annotation encoding="application/x-tex">w^{1} \leftarrow w^{0}-\left.\eta \frac{\partial L}{\partial w}\right|_{w=w^{0}, b=b^{0}} \quad b^{1} \leftarrow b^{0}-\left.\eta \frac{\partial L}{\partial b}\right|_{w=w^{0}, b=b^{0}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.4159em;vertical-align:-0.5358em;"></span><span class="minner"><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-2.85em;"><span class="pstrut" style="height:3.2em;"></span><span style="width:0.333em;height:1.200em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.333em' height='1.200em' viewBox='0 0 333 1200'><path d='M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1227em;"><span style="top:-2.3003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">b</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.4159em;vertical-align:-0.5358em;"></span><span class="minner"><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">b</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-2.85em;"><span class="pstrut" style="height:3.2em;"></span><span style="width:0.333em;height:1.200em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.333em' height='1.200em' viewBox='0 0 333 1200'><path d='M145 15 v585 v0 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v0 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v0 v585 h43z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1227em;"><span style="top:-2.3003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">b</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5358em;"><span></span></span></span></span></span></span></span></span></span></strong></p>
<p>同理No local optimal无局部最优</p>
<p>整理成一个简介的公式，即梯度</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∇</mi><mi>L</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>w</mi></mrow></mfrac></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>b</mi></mrow></mfrac></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mtext> gradient </mtext></mrow><annotation encoding="application/x-tex">\nabla L=\left[\begin{array}{l}
\frac{\partial L}{\partial w} \\
\frac{\partial L}{\partial b}
\end{array}\right] \text { gradient }</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">∇</span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4802em;vertical-align:-0.9901em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4901em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-2.3699em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">b</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9901em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord"> gradient </span></span></span></span></span></p>
</blockquote>
<p>以上操作就可以得到线性回归的损失函数最小模型</p>
<p><strong>小插曲：如何评价模型？</strong></p>
<img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20221006203707421.png" alt="image-20221006203707421" style="zoom: 50%;" />
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>N</mi><mn>10</mn></mfrac><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msup><mi>e</mi><mi>n</mi></msup><mo separator="true">,</mo><mtext>其中</mtext><msup><mi>e</mi><mi>n</mi></msup><mtext>为点到模型的距离</mtext></mrow><annotation encoding="application/x-tex">\frac{N}{10} \sum_{n=1}^{N} e^{n},其中e^{n}为点到模型的距离</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3262em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord cjk_fallback">其中</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span><span class="mord cjk_fallback">为点到模型的距离</span></span></span></span></p>
<p>一般训练集会比测试集的小，因为原本模型求解损失函数最小就是基于训练集的</p>
<p>是否有更好的1元N次线性模型</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>b</mi><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><mo>⋅</mo><msub><mi>x</mi><mrow><mi>c</mi><mi>p</mi></mrow></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><mo>⋅</mo><msup><mrow><mo fence="true">(</mo><msub><mi>x</mi><mrow><mi>c</mi><mi>p</mi></mrow></msub><mo fence="true">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">y=b+w_{1} \cdot x_{c p}+w_{2} \cdot\left(x_{c p}\right)^{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.5945em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.5945em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2401em;vertical-align:-0.2861em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.954em;"><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>同理通过梯度下降求解最小损失函数时的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo separator="true">,</mo><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">b,w_{1},w_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>…还可以使用更高次方的模型</p>
<p>在训练集上面表现更为优秀的模型，为什么在测试集上效果反而变差了</p>
<p><strong>小插曲：过拟合问题的出现？</strong></p>
<blockquote>
<p>如图所示，每一个模型结果都是一个集合，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mtext>次模型包</mtext><mo>⊇</mo><mn>4</mn><mtext>次模型</mtext><mo>⊇</mo><mn>3</mn><mtext>次模型</mtext></mrow><annotation encoding="application/x-tex">5次模型包 \supseteq  4次模型 \supseteq  3次模型</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord">5</span><span class="mord cjk_fallback">次模型包</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⊇</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord">4</span><span class="mord cjk_fallback">次模型</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⊇</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">3</span><span class="mord cjk_fallback">次模型</span></span></span></span>所以<mark>在4次模型里面找到的最佳模型，肯定不会比5次模型里面找到更差</mark></p>
<p>将错误率结果图形化展示，发现3次方以上的模型，已经出现了过拟合的现象：</p>
<img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20221006205944392.png" alt="image-20221006205944392" style="zoom: 50%;" />
</blockquote>
<p>优化</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Step1优化：2个input的四个线性模型是合并到一个线性模型中</p>
</li>
<li class="lvl-2">
<p>Step2优化：如果希望模型更强大表现更好（更多参数，更多input）</p>
</li>
<li class="lvl-2">
<p>Step3优化：加入正则化</p>
<ul class="lvl-2">
<li class="lvl-4">更多特征，但是权重 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> 可能会使某些特征权值过高，仍旧导致overfitting，所以加入正则化<img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20221006211713472.png" alt="image-20221006211713472" style="zoom:50%;" />
<ul class="lvl-4">
<li class="lvl-6"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">w_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>越小，越平滑的function。但过小又回成水平线。需要调参<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span>,找到最合适的<img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20221006212324682.png" alt="image-20221006212324682" style="zoom:50%;" /></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="二-偏差与方差">二、偏差与方差</h2>
<h3 id="数据模型的复杂度">数据模型的复杂度</h3>
<p>考虑的数据模型越复杂，训练效果越好，而预测可能出现过拟合现象。</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/方差与偏差.jpeg" alt="方差与偏差" style="zoom: 50%;" />
<h4 id="textcolor-red-考-方差与偏差和模型的复杂关系是什么"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mtext>方差与偏差和模型的复杂关系是什么</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.方差与偏差和模型的复杂关系是什么}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">方差与偏差和模型的复杂关系是什么</span></span></span></span></h4>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>来自ChatGPT</p>
</li>
</ul>
<p>方差和偏差是评估机器学习模型性能的两个重要指标。它们之间存在一定的关系，特别是与模型复杂度有关。</p>
<p>偏差是指模型的预测值与真实值之间的差异，它衡量的是模型的拟合能力。偏差大的模型容易欠拟合，即对训练数据的拟合不够好，而对测试数据的预测能力也会较差。</p>
<p>方差是指模型预测值的变化范围，它衡量的是模型的泛化能力。方差大的模型容易过拟合，即对训练数据的拟合过于好，而对测试数据的预测能力较差。</p>
<p>在模型复杂度较低时，偏差通常很高，方差很低。这是因为简单的模型可能无法很好地拟合数据，因此在不同的训练数据上得到的预测结果差别不大，方差较小。但是，在不同的训练数据上得到的预测结果与真实值之间的差距较大，偏差较高。</p>
<p>随着模型复杂度的增加，偏差逐渐降低，方差逐渐增加。这是因为复杂的模型可以更好地拟合数据，因此在不同的训练数据上得到的预测结果与真实值之间的差距较小，偏差较低。但是，复杂的模型也容易过拟合，即对训练数据的拟合过于好，而对测试数据的预测能力较差，方差较高。</p>
<p>因此，选择合适的模型复杂度可以在偏差和方差之间取得平衡，从而达到较好的预测性能。一般而言，可以使用交叉验证等技术来帮助选择合适的模型复杂度。</p>
</blockquote>
<h4 id="textcolor-red-考-判断-如果你的模型甚至不能拟合训练样本-那么你就有很大的偏差"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mtext>判断</mtext><mo>−</mo><mtext>如果你的模型甚至不能拟合训练样本，那么你就有很大的偏差</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.判断-如果你的模型甚至不能拟合训练样本，那么你就有很大的偏差}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">判断</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin" style="color:red;">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">如果你的模型甚至不能拟合训练样本，那么你就有很大的偏差</span></span></span></span></h4>
<blockquote>
<p><mark>正确</mark>：欠拟合，大偏差</p>
<p>以下ppt前一页即是考试题的解释</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20220920173540229.png" alt="image-20220920173540229" style="zoom: 25%;" />
<p>欠拟合：对训练样本的一般性质尚未学好。在训练集及测试集上的表现都不好。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⟶</mo></mrow><annotation encoding="application/x-tex">\longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.522em;vertical-align:-0.011em;"></span><span class="mrel">⟶</span></span></span></span>偏差大</p>
<ul class="lvl-1">
<li class="lvl-2">
<p>低拟合简单的模型会有大的偏差，小的方差；重建你的模型，比如增加更多的特征，换个复杂模型</p>
</li>
<li class="lvl-2">
<p>过拟合复杂的模型会有小的偏差，大的方差；增加数据没法增加数据时=&gt;规则化，</p>
</li>
</ul>
</blockquote>
<h4 id="欠拟合与过拟合">欠拟合与过拟合</h4>
<p>欠拟合：对训练样本的一般性质尚未学好。在训练集及测试集上的表现都不好。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⟶</mo></mrow><annotation encoding="application/x-tex">\longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.522em;vertical-align:-0.011em;"></span><span class="mrel">⟶</span></span></span></span>偏差大</p>
<p>过拟合：训练集的训练效果好，但是测试集上的效果不好。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⟶</mo></mrow><annotation encoding="application/x-tex">\longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.522em;vertical-align:-0.011em;"></span><span class="mrel">⟶</span></span></span></span>方差大</p>
<h5 id="解决路线">解决路线</h5>
<img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20230202194701119.png" alt="image-20230202194701119" style="zoom: 67%;" />
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>训练集loss</p>
<ul class="lvl-3">
<li class="lvl-4">
<p>大 -&gt;</p>
<ul class="lvl-5">
<li class="lvl-6">
<p>model bias问题</p>
<ul class="lvl-7">
<li class="lvl-8">增加模型复杂度</li>
</ul>
</li>
<li class="lvl-6">
<p>optimization问题</p>
</li>
</ul>
</li>
<li class="lvl-4">
<p>小 -&gt; 测试集loss</p>
<ul class="lvl-5">
<li class="lvl-6">
<p>大 -&gt;</p>
<ul class="lvl-7">
<li class="lvl-8">
<p>overfitting问题</p>
<ul class="lvl-9">
<li class="lvl-10">更多训练数据</li>
<li class="lvl-10">数据扩展</li>
<li class="lvl-10">降低模型弹性</li>
</ul>
</li>
<li class="lvl-8">
<p>mismatch问题</p>
<ul class="lvl-9">
<li class="lvl-10">（训练集与测试集分布差得多）</li>
</ul>
</li>
</ul>
</li>
<li class="lvl-6">
<p>小 -&gt; success</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="注意">注意</h3>
<ul class="lvl-1">
<li class="lvl-2">
<p>model够不够大</p>
<ul class="lvl-3">
<li class="lvl-4">
<p>一个建议判断方法</p>
<ul class="lvl-5">
<li class="lvl-6">
<img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20230202194741271.png" alt="image-20230202194741271" style="zoom: 67%;" />
</li>
</ul>
</li>
</ul>
</li>
<li class="lvl-2">
<p>overfitting的极端例子</p>
<ul class="lvl-3">
<li class="lvl-4">x当做输入的时候,我们就去比对这个x,有没有出现在训练集裡面,如果x有出现在训练集裡面,就把它对应的ŷ当做输出,如果x没有出现在训练集裡面,就输出一个随机的值</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="神经网络neural-network">神经网络Neural Network</h3>
<p>神经网络的基础：神经元</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020113246762.png" alt="image-20221020113246762" style="zoom:50%;" />
<h4 id="激活函数">激活函数</h4>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020113339209.png" alt="image-20221020113339209" style="zoom:50%;" />
<h5 id="神经网络">神经网络</h5>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020113611322.png" alt="image-20221020113611322" style="zoom:50%;" />
<p>多个神经元组成一个隐藏层，多个隐藏层以及输入和输出层构成了一个神经网络：</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020115610406.png" alt="image-20221020115610406" style="zoom:50%;" />
<h5 id="textcolor-red-课后作业-神经网络泛化-2022-9-23"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>课后作业</mtext><mi mathvariant="normal">.</mi><mtext>神经网络泛化</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{课后作业.神经网络泛化}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">课后作业</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">神经网络泛化</span></span></span></span>-2022-9-23</h5>
<h3 id="神经网络为什么不会一直过拟合-反而有良好的泛化能力"><mark>神经网络为什么不会一直过拟合，反而有良好的泛化能力。</mark></h3>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>来自CharGPT</p>
</li>
</ul>
<p>神经网络之所以能够在训练数据上进行良好的拟合，同时又具有较好的泛化能力，是由于神经网络本身具有一些特性和训练方法可以避免过拟合并提高泛化能力。以下是一些可能的原因：</p>
<ol>
<li class="lvl-3">
<p>参数共享：神经网络中的参数通常是共享的，即多个神经元使用相同的权重，这样可以使得网络更加简单，降低过拟合的风险。</p>
</li>
<li class="lvl-3">
<p>正则化：正则化是一种降低模型复杂度的方法，它通过在损失函数中添加惩罚项来避免模型过度拟合训练数据。在神经网络中，L1正则化和L2正则化都可以有效地降低模型复杂度，并提高泛化能力。</p>
</li>
<li class="lvl-3">
<p>数据增强：数据增强是通过一些变换方法扩充原始训练数据的方法。通过数据增强，可以使得训练数据更加丰富多样，从而提高模型的泛化能力。</p>
</li>
<li class="lvl-3">
<p>集成学习：集成学习是将多个不同的模型进行组合以获得更好的泛化能力的方法。在神经网络中，常见的集成学习方法包括Dropout和Bagging等。</p>
</li>
<li class="lvl-3">
<p>停止训练的时机：神经网络的训练过程通常会进行多个epoch，但是在一定程度上，过多的训练容易导致过拟合。因此，可以设置一些停止训练的条件，如达到一定的训练次数或者验证集误差不再下降等，以避免过度拟合。</p>
</li>
</ol>
<p>综上所述，神经网络能够在训练数据上获得良好的拟合效果并具有较好的泛化能力，是由于神经网络具有一些特性和训练方法可以避免过拟合，并提高泛化能力。</p>
</blockquote>
<blockquote>
<p>偏向于拟合光滑函数，从而捕获到数据中出现的全局性结构而不是过度拟合单个样本。</p>
<ul class="lvl-1">
<li class="lvl-2">泛化能力（generalization ability）是指机器学习算法对新鲜样本的适应能力。</li>
</ul>
</blockquote>
<h3 id="linear-regression-线性回归">Linear Regression（线性回归）</h3>
<h4 id="step-1-model">Step 1: Model</h4>
<blockquote>
<p>建立模型</p>
</blockquote>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020121437926.png" alt="image-20221020121437926" style="zoom:50%;" />
<h4 id="step-2-goodness-of-function">Step 2: Goodness of Function</h4>
<blockquote>
<p>评判方程的效果好坏</p>
</blockquote>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020122319077.png" alt="image-20221020122319077" style="zoom: 150%;" />
<h4 id="step-3-best-function">Step 3: Best Function</h4>
<blockquote>
<p>通过梯度下降的方式选出最好的方程式</p>
</blockquote>
<p>1️⃣</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020122614363.png" alt="image-20221020122614363" style="zoom:50%;" />
<p>2️⃣先单独考虑一个变量的梯度</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020123116925.png" alt="image-20221020123116925"  />
<p>3️⃣之后考虑多个变量的梯度</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020123234604.png" alt="image-20221020123234604" style="zoom:50%;" />
<p>得到的梯度如下：</p>
<p><img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020124419692.png" alt="image-20221020124419692"></p>
<p>示意图：</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020124605173.png" alt="image-20221020124605173" style="zoom: 67%;" />
<p>梯度下降可能会收敛到局部最优：</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020124806461.png" alt="image-20221020124806461" style="zoom:50%;" />
<h4 id="计算平均误差">计算平均误差</h4>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020125549475.png" alt="image-20221020125549475" style="zoom:50%;" />
<blockquote>
<p>分别计算Training Data和Testing Data的平均误差，之后比价两者的平均误差发现后者的平均误差一般比前者的平均误差大，毕竟函数式<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>b</mi><mo>+</mo><mi>w</mi><mo>⋅</mo><msub><mi>x</mi><mrow><mi>c</mi><mi>p</mi></mrow></msub></mrow><annotation encoding="application/x-tex">y=b+w\cdot x_{cp}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4445em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>是由Training Data训练得到的。</p>
</blockquote>
<p>以上一次方程的误差较大，这个时候我们可以采用高次多项式来拟合数据：</p>
<p>比如：</p>
<p><img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020130102700.png" alt="image-20221020130102700"></p>
<p><img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020130121830.png" alt="image-20221020130121830"></p>
<p>越复杂的模型对Training Data的平均误差越小，但是对Testing Data的平均误差却可能很大，这就是过拟合：</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020130335681.png" alt="image-20221020130335681" style="zoom:50%;" />
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020130503210.png" alt="image-20221020130503210" style="zoom:50%;" />
<blockquote>
<p>我们应该选择对Training Data和Testing Data的平均误差都很小，且两者的平均误差相差不大的模型。</p>
</blockquote>
<h5 id="regulation规整化-正则化">Regulation规整化（正则化）</h5>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221020144310277.png" alt="image-20221020144310277" style="zoom: 50%;" />
<blockquote>
<p>正则化可以解决过拟合问题：通过使权重衰减，降低实际结果与预测结果之差的累和对整体结果的影响，从而使得方程的曲线更加的光滑，而一般认为光滑的方程更可能是正确的。</p>
<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/jialibang/article/details/108991631">(77条消息) 正则化为什么可以防止过拟合_jk英菲尼迪的博客-CSDN博客_正则化为什么能防止过拟合</a></p>
</blockquote>
<h3 id="logistic-regression-逻辑回归">Logistic Regression（逻辑回归）</h3>
<h5 id="什么是生成模型？">什么是生成模型？</h5>
<blockquote>
<p>计算一个给定的x是属于哪个类型的，比较P(C_1|x)和P(C_ 2 | x)的值，哪个类别的概率大x就属于哪个类别。</p>
<p>P(C_1|x)和P(C_ 2 | x)的值将从训练集中获得。</p>
<p><img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221028231017004.png" alt="image-20221028231017004"></p>
</blockquote>
<p>监督学习方法可以分为生成方法（generative approach）和判别方法（discriminative approach）。所学到的模型分别称为生成模型（generative model）和判别模型（discriminative model）。生成方法由数据学习联合概率分布，然后求出条件概率分布作为预测的模型，即生成模型。</p>
<h3 id="机器学习的三步骤：">机器学习的三步骤：</h3>
<ol>
<li class="lvl-3">
<p>定义模型</p>
</li>
<li class="lvl-3">
<p>定义损失函数——方法：梯度下降</p>
</li>
<li class="lvl-3">
<p>进行函数求解</p>
</li>
</ol>
<h4 id="1-梯度下降">1️⃣梯度下降</h4>
<blockquote>
<p>梯度下降参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/68468520">梯度下降算法（Gradient Descent)的原理和实现步骤 - 知乎 (zhihu.com)</a></p>
<p>多次求解求平均得到平滑曲线。</p>
</blockquote>
<p><strong>梯度下降的目的，就是为了最小化损失函数。</strong></p>
<p><img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/v2-79eecd15feeaececb8a1b651ed88b6be_r.jpg" alt="preview"></p>
<blockquote>
<p>此时如果求出A点的梯度  ，便可以知道如果我们向右移动，可以使损失函数的值变得更小。</p>
</blockquote>
<h5 id="学习率">学习率</h5>
<p>如果学习率 α 设置得过大，有可能我们会错过损失函数的最小值；如果设置得过小，可能我们要迭代式子非常多次才能找到最小值，会耗费较多的时间。因此，在实际应用中，我们需要为学习率 α 设置一个合适的值。</p>
<h5 id="设置学习率的两种方法">设置学习率的两种方法</h5>
<blockquote>
<p>学习率衰减参考：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/7311e7151661">机器学习 | 优化——调整学习率 - 简书 (jianshu.com)</a></p>
<p>概述：</p>
<p>学习率在一开始要保持大些来保证收敛速度，在收敛到最优点附近时要小些以避免来回震荡。</p>
<p>实例：</p>
<p>E.g. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>t</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> decay: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>η</mi><mi>t</mi></msup><mo>=</mo><mi>η</mi><mi mathvariant="normal">/</mi><msqrt><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msqrt></mrow><annotation encoding="application/x-tex">\eta^t=\eta / \sqrt{t+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.988em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7936em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1156em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8656em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span><span style="top:-2.8256em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1744em;"><span></span></span></span></span></span></span></span></span></p>
</blockquote>
<p><strong>Adagrad算法</strong>：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>←</mo><msup><mi>w</mi><mi>t</mi></msup><mo>−</mo><mfrac><mi>η</mi><msqrt><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>t</mi></msubsup><msup><mrow><mo fence="true">(</mo><msup><mi>g</mi><mi>i</mi></msup><mo fence="true">)</mo></mrow><mn>2</mn></msup></mrow></msqrt></mfrac><msup><mi>g</mi><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">w^{t+1} \leftarrow w^t-\frac{\eta}{\sqrt{\sum_{i=0}^t\left(g^i\right)^2}} g^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8769em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7936em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.6232em;vertical-align:-0.8296em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.4491em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0585em;"><span class="svg-align" style="top:-3.4286em;"><span class="pstrut" style="height:3.4286em;"></span><span class="mord mtight" style="padding-left:1.19em;"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8365em;"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-2.8971em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3214em;"><span></span></span></span></span></span></span><span class="minner mtight"><span class="minner mtight"><span class="mopen mtight delimcenter" style="top:0em;"><span class="mtight">(</span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7571em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span><span class="mclose mtight delimcenter" style="top:0em;"><span class="mtight">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8645em;"><span style="top:-2.9042em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.0305em;"><span class="pstrut" style="height:3.4286em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.5429em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.5429em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3981em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">η</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8296em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7936em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mtext> |First derivative| </mtext><mtext> Second derivative </mtext></mfrac></mrow><annotation encoding="application/x-tex">\frac{\text { |First derivative| }}{\text { Second derivative }}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.355em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight"> Second derivative </span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight"> |First derivative| </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⟶</mo></mrow><annotation encoding="application/x-tex">\longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.522em;vertical-align:-0.011em;"></span><span class="mrel">⟶</span></span></span></span>通过一阶衍生物的绝对值除以二阶衍生物得到最好的步长。</p>
<blockquote>
<p>EI会议：1、2、3阶——分数降低或者不算</p>
</blockquote>
<blockquote>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>搞清论文问题和研究是方向</mtext><mi mathvariant="normal">/</mi><mtext>算法的改进点等。</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{搞清论文问题和研究是方向/算法的改进点等。}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord cjk_fallback" style="color:red;">搞清论文问题和研究是方向</span><span class="mord" style="color:red;">/</span><span class="mord cjk_fallback" style="color:red;">算法的改进点等。</span></span></span></span></p>
</blockquote>
<h5 id="textcolor-red-课后作业-协方差矩阵σ相同accuracy增加-2022-9-27"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>课后作业</mtext><mi mathvariant="normal">.</mi><mtext>协方差矩阵</mtext><mi mathvariant="normal">Σ</mi><mtext>相同</mtext><mi>a</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mtext>增加</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{课后作业.协方差矩阵Σ相同accuracy增加}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord cjk_fallback" style="color:red;">课后作业</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">协方差矩阵</span><span class="mord" style="color:red;">Σ</span><span class="mord cjk_fallback" style="color:red;">相同</span><span class="mord mathnormal" style="color:red;">a</span><span class="mord mathnormal" style="color:red;">cc</span><span class="mord mathnormal" style="color:red;">u</span><span class="mord mathnormal" style="margin-right:0.02778em;color:red;">r</span><span class="mord mathnormal" style="color:red;">a</span><span class="mord mathnormal" style="margin-right:0.03588em;color:red;">cy</span><span class="mord cjk_fallback" style="color:red;">增加</span></span></span></span>-2022-9-27</h5>
<p>思考Σ相同的时候，accuracy为什么会增加？</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20220927173552056.png" alt="image-20220927173552056" style="zoom:50%;" />
<blockquote>
<p>协方差矩阵Σ 是一个对称矩阵，协方差矩阵，因而决定了多维高斯分布的形状。协方差矩阵Σ是和输入特征（大小）的平方成正比，所以当特征很多的时候，协方差矩阵是可以增长很快的。此时考虑到模型参数过多时候就容易过拟合，而共用协方差矩阵的话会使得参数变少，过拟合变弱了，准确率也就上升了。</p>
<p><mark>模型参数过多，就容易发生过拟合，共用协方差矩阵使得参数变少，过拟合的程度变弱了，准确率也就上升了。</mark></p>
</blockquote>
<h4 id="启动函数-激活函数-：将范围限定在-0-1">启动函数（激活函数）：将范围限定在[0,1]</h4>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20220930081913017.png" alt="image-20220930081913017" style="zoom:50%;" />
<h6 id="交叉熵函数定义：">交叉熵函数定义：</h6>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20220930083755084.png" alt="image-20220930083755084" style="zoom:50%;" />
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20220930083930554.png" alt="image-20220930083930554" style="zoom: 50%;" />
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221004160947492.png" alt="image-20221004160947492" style="zoom:50%;" />
<h5 id="textcolor-red-课后作业-逻辑回归分界线-2022-9-30"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>课后作业</mtext><mi mathvariant="normal">.</mi><mtext>逻辑回归分界线</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{课后作业.逻辑回归分界线}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">课后作业</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">逻辑回归分界线</span></span></span></span>-2022-9-30</h5>
<p>能否找一条线将四个区分出来</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20220930094126581.png" alt="image-20220930094126581" style="zoom:33%;" />
<blockquote>
<p>不能，逻辑回归的分界线是一条直线，而一条直线是不能将红蓝两类分开的，所以需要对特征进行转换，通过特征转换使得能够通过直线分开的红蓝两个特征。</p>
<p>转换为更有利于后面分类的特征。</p>
</blockquote>
<h2 id="六-深度学习">六、深度学习</h2>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221004163212224.png" alt="image-20221004163212224" style="zoom:33%;" />
<p>神经网络：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>多少层</p>
</li>
<li class="lvl-2">
<p>每层多少神经元</p>
</li>
</ul>
<blockquote>
<p>分类问题使用交叉熵定义激活函数。</p>
<p>交叉熵：</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221004165848429.png" alt="image-20221004165848429" style="zoom:50%;" />
</blockquote>
<h4 id="梯度下降">梯度下降</h4>
<ul class="lvl-0">
<li class="lvl-2">
<p>随机梯度下降法的第一步是随机化整个数据集</p>
</li>
<li class="lvl-2">
<p>计算梯度</p>
</li>
<li class="lvl-2">
<p>不断反复，更新参数，直到得到最好的参数使得损失函数的值最小</p>
</li>
</ul>
<blockquote>
<p>具体流程：θ是一组包含权重和偏差的参数集合，随机找一个初试值，接下来计算一下每个参数对应偏微分，得到的一个偏微分的集合∇<em>L</em>就是梯度,有了这些偏微分，我们就可以不断更新梯度得到新的参数，这样不断反复进行，就能得到一组最好的参数使得损失函数的值最小。</p>
</blockquote>
<h3 id="textcolor-red-考-反向传播增加梯度下降效率"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mtext>反向传播增加梯度下降效率</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.反向传播增加梯度下降效率}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">反向传播增加梯度下降效率</span></span></span></span></h3>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>来自ChatGPT</p>
</li>
</ul>
<p>反向传播是一种有效的训练神经网络的方法，可以通过计算网络参数对损失函数的梯度来进行梯度下降优化。</p>
<p>梯度下降是一种常用的优化方法，它通过沿着损失函数的负梯度方向更新网络参数，从而使得损失函数逐渐减小。然而，对于深度神经网络等复杂模型，损失函数往往具有大量的参数，使得梯度计算非常困难，从而导致优化过程非常缓慢。</p>
<p>反向传播通过使用链式法则，将损失函数的梯度从输出层向输入层依次传递，从而计算每个网络参数对于损失函数的梯度，从而加速了梯度下降的过程。具体来说，反向传播可以在一次前向传播计算中计算出所有权重的梯度，从而使得梯度下降的更新更加高效。</p>
<p>此外，反向传播的计算速度也得到了很大的提升，这主要得益于现代计算机的并行计算能力以及深度学习框架的优化。通过在计算图上高效地计算梯度，反向传播可以在较短的时间内完成整个神经网络的梯度计算，从而大大提高了梯度下降的效率。</p>
<p>因此，反向传播在训练深度神经网络等复杂模型时，可以大大加快梯度下降的速度，提高模型的训练效率和性能。</p>
</blockquote>
<blockquote>
<p>为什么使用反向传播可以增加梯度下降的效率？</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221004171211792.png" alt="image-20221004171211792" style="zoom: 50%;" />
<p>先前向传播计算链式求导得到输出值：</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221004172415410.png" alt="image-20221004172415410" style="zoom:50%;" />
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221004173135758.png" alt="image-20221004173135758" style="zoom:50%;" />
<p>之后将得到的值依次往前面带入得到</p>
</blockquote>
<p>sigmod函数可以作为激活函数，也是逻辑回归函数</p>
<h3 id="卷积神经网络">卷积神经网络</h3>
<blockquote>
<p>看网课参考：</p>
</blockquote>
<h3 id="textcolor-red-考-convolution-maxpooling计算"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mi>C</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi>o</mi><mi>l</mi><mi>u</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>M</mi><mi>a</mi><mi>x</mi><mi>P</mi><mi>o</mi><mi>o</mi><mi>l</mi><mi>i</mi><mi>n</mi><mi>g</mi><mtext>计算</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.Convolution MaxPooling计算}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord mathnormal" style="margin-right:0.07153em;color:red;">C</span><span class="mord mathnormal" style="color:red;">o</span><span class="mord mathnormal" style="color:red;">n</span><span class="mord mathnormal" style="margin-right:0.03588em;color:red;">v</span><span class="mord mathnormal" style="color:red;">o</span><span class="mord mathnormal" style="margin-right:0.01968em;color:red;">l</span><span class="mord mathnormal" style="color:red;">u</span><span class="mord mathnormal" style="color:red;">t</span><span class="mord mathnormal" style="color:red;">i</span><span class="mord mathnormal" style="color:red;">o</span><span class="mord mathnormal" style="color:red;">n</span><span class="mord mathnormal" style="margin-right:0.10903em;color:red;">M</span><span class="mord mathnormal" style="color:red;">a</span><span class="mord mathnormal" style="color:red;">x</span><span class="mord mathnormal" style="margin-right:0.13889em;color:red;">P</span><span class="mord mathnormal" style="color:red;">oo</span><span class="mord mathnormal" style="margin-right:0.01968em;color:red;">l</span><span class="mord mathnormal" style="color:red;">in</span><span class="mord mathnormal" style="margin-right:0.03588em;color:red;">g</span><span class="mord cjk_fallback" style="color:red;">计算</span></span></span></span></h3>
<p>现有k * K的图片以及w* w的filter,使用filter最后能够得到的图片的大小？（可以推导出通用表达式）</p>
<blockquote>
<p>包含1、2、3</p>
</blockquote>
<h6 id="1-convolution计算过程：">1、Convolution计算过程：</h6>
<p>1️⃣</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221007082531184.png" alt="image-20221007082531184" style="zoom:50%;" />
<p>2️⃣</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221007082634487.png" alt="image-20221007082634487" style="zoom:50%;" />
<h6 id="2-max-pooling">2、Max Pooling</h6>
<p>选出每个框中的最大元素作为该框的代表元素：</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221007084033973.png" alt="image-20221007084033973" style="zoom:50%;" />
<p>经过Max Pooling之后，得到2 * 2的图片矩阵</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221007084331076.png" alt="image-20221007084331076" style="zoom:50%;" />
<blockquote>
<p>在CNN中，<mark>不一定需要Max Pooling步骤</mark>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>可能会出一个判断题！</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{可能会出一个判断题！}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">可能会出一个判断题！</span></span></span></span></p>
</blockquote>
<h6 id="3-flatten">3、Flatten</h6>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221007084550253.png" alt="image-20221007084550253" style="zoom:50%;" />
<hr>
<h6 id="keras">Keras</h6>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221007090017917.png" alt="image-20221007090017917" style="zoom:50%;" />
<h3 id="textcolor-red-考-convolution-maxpooling计算"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mi>C</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi>o</mi><mi>l</mi><mi>u</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>M</mi><mi>a</mi><mi>x</mi><mi>P</mi><mi>o</mi><mi>o</mi><mi>l</mi><mi>i</mi><mi>n</mi><mi>g</mi><mtext>计算</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.Convolution MaxPooling计算}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord mathnormal" style="margin-right:0.07153em;color:red;">C</span><span class="mord mathnormal" style="color:red;">o</span><span class="mord mathnormal" style="color:red;">n</span><span class="mord mathnormal" style="margin-right:0.03588em;color:red;">v</span><span class="mord mathnormal" style="color:red;">o</span><span class="mord mathnormal" style="margin-right:0.01968em;color:red;">l</span><span class="mord mathnormal" style="color:red;">u</span><span class="mord mathnormal" style="color:red;">t</span><span class="mord mathnormal" style="color:red;">i</span><span class="mord mathnormal" style="color:red;">o</span><span class="mord mathnormal" style="color:red;">n</span><span class="mord mathnormal" style="margin-right:0.10903em;color:red;">M</span><span class="mord mathnormal" style="color:red;">a</span><span class="mord mathnormal" style="color:red;">x</span><span class="mord mathnormal" style="margin-right:0.13889em;color:red;">P</span><span class="mord mathnormal" style="color:red;">oo</span><span class="mord mathnormal" style="margin-right:0.01968em;color:red;">l</span><span class="mord mathnormal" style="color:red;">in</span><span class="mord mathnormal" style="margin-right:0.03588em;color:red;">g</span><span class="mord cjk_fallback" style="color:red;">计算</span></span></span></span></h3>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221007091052106.png" alt="image-20221007091052106" style="zoom:50%;" />
<blockquote>
<p>假设我们input一个1 *28 * 28的image，你就可以写model.add(Convolution2D( 25, 3, 3, Input_shape=(28,28,1)))。通过convplution以后得到output是25 *26 26(25个filter，通过3 *3得到26 * 26)。然后做max pooling，2 *2一组选择 max value得到 25 *13 * 13</p>
<p>然后在做一次convolution，假设我在这选50个filter，每一个filter是3 *3时，那么现在的channel就是50。13 *13的image通过3 *3的filter，就成11 *11，然后通过2 *2的Max Pooling，变成了50 *5 *5</p>
<p>在第一个convolution layer里面，每一个filter有9个参数，在第二个convolution layer里面，虽然每一个filter都是3 *3，但不是3 *3个参数，<mark>因为它input channel 是25个，所以它的参数是3 *3 *25(225)</mark>。</p>
</blockquote>
<p>CNN的三个特点：</p>
<ol>
<li class="lvl-3">
<p>局部感知，简单来说，卷积核的大小一般小于输入图像的大小（如果等于则是全连接），因此卷积提取出的特征会更多地关注局部 —— 这很符合日常我们接触到的图像处理。而每个神经元其实没有必要对全局图像进行感知，只需要对局部进行感知，然后在更高层将局部的信息综合起来就得到了全局的信息。</p>
</li>
<li class="lvl-3">
<p>参数共享，参数共享最大的作用莫过于很大限度地减少运算量了。</p>
</li>
<li class="lvl-3">
<p>多核，一般我们都不会只用一个卷积核对输入图像进行过滤，因为一个核的参数是固定的，其提取的特征也会单一化。这就有点像是我们平时如何客观看待事物，必须要从多个角度分析事物，这样才能尽可能地避免对该事物产生偏见。我们也需要多个卷积核对输入图像进行卷积。</p>
</li>
</ol>
<p>CNN的应用：</p>
<ol>
<li class="lvl-3">
<p>图片</p>
</li>
<li class="lvl-3">
<p>语音</p>
</li>
<li class="lvl-3">
<p>文本</p>
</li>
</ol>
<h4 id="深度学习的模块化">深度学习的模块化</h4>
<p>问题1：为什么变高比变宽好呢？</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221011164416400.png" alt="image-20221011164416400" style="zoom:50%;" />
<p>1️⃣直接利用四个训练集去训练分类器</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221011163822838.png" alt="image-20221011163822838" style="zoom:50%;" />
<p>2️⃣先训练第一层分类器（base Classifier），再训练第二层分类器</p>
<ul class="lvl-0">
<li class="lvl-2">
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221011164008381.png" alt="image-20221011164008381" style="zoom:50%;" />
</li>
<li class="lvl-2">
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221011164109653.png" alt="image-20221011164109653" style="zoom:50%;" />
</li>
</ul>
<p>问题2：深度学习和模组化有什么关系？</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221011164454264.png" alt="image-20221011164454264" style="zoom:50%;" />
<h4 id="普遍性定理">普遍性定理</h4>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221011170600015.png" alt="image-20221011170600015" style="zoom:50%;" />
<h3 id="textcolor-red-考-一隐藏层表所有函数而多层"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mtext>一隐藏层表所有函数而多层</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.一隐藏层表所有函数而多层}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">一隐藏层表所有函数而多层</span></span></span></span></h3>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>来自ChatGPT</p>
</li>
</ul>
<p>虽然理论上一个具有足够数量的神经元的单层神经网络可以表示所有函数，但在实际应用中，使用多层神经网络可以更好地解决一些实际问题。以下是一些可能的原因：</p>
<ol>
<li class="lvl-3">
<p>更强的表达能力：深层神经网络具有更强的表达能力，可以更好地拟合具有复杂结构的数据。多层神经网络可以通过将低级特征组合成更高级别的特征，来学习数据中的更抽象的表示。</p>
</li>
<li class="lvl-3">
<p>更好的泛化能力：深层神经网络可以通过训练过程中的参数共享、正则化等方式来避免过拟合，并且具有更好的泛化能力。与单层神经网络相比，深层神经网络通常能够更好地适应新的数据，从而获得更好的泛化性能。</p>
</li>
<li class="lvl-3">
<p>更高的效率：深层神经网络通常可以通过并行计算等方式来加速模型训练和推断过程，从而在实际应用中具有更高的效率。此外，深层神经网络通常具有更少的神经元数量，因此可以更快地处理大规模数据集。</p>
</li>
</ol>
<p>综上所述，尽管单层神经网络在理论上可以表示所有函数，但深层神经网络在实际应用中通常具有更好的表达能力、泛化能力和效率，因此在许多领域中得到广泛的应用。</p>
</blockquote>
<blockquote>
<p>一个隐藏层就可以表示所有函数，为什么要使用多层？</p>
<p>回：但是这个理论没有告诉我们的是，它只告诉我们可能性，但是它没有告诉我们说要做到这件事情到底有多有效率。没错，你只要有够多的参数，hidden layer够宽，你就可以描述任何的function。但是这个理论没有告诉我们的是，当我们用这一件事(我们只用一个hidde layer来描述function的时候)它其实是没有效率的。当你有more layer(high structure)你用这种方式来描述你的function的时候，它是比较有效率的。</p>
</blockquote>
<h5 id="无监督学习-深度自编码器">无监督学习-深度自编码器</h5>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221011173843036.png" alt="image-20221011173843036" style="zoom: 50%;" />
<blockquote>
<p>Auto-encoder包含：</p>
<ul class="lvl-1">
<li class="lvl-2">编码</li>
<li class="lvl-2">解码</li>
</ul>
</blockquote>
<h6 id="recap-pca">Recap PCA</h6>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221014080432006.png" alt="image-20221014080432006" style="zoom:50%;" />
<h6 id="deep-auto-encoder">Deep Auto-encoder</h6>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221014080448278.png" alt="image-20221014080448278" style="zoom:50%;" />
<h6 id="deep-auto-encoder对噪声点的处理">Deep Auto-encoder对噪声点的处理</h6>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221014080904171.png" alt="image-20221014080904171" style="zoom:50%;" />
<p>使用像素级的欧式距离进行计算的到的结果图片中的内容差距较大</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221014082534044.png" alt="image-20221014082534044" style="zoom:50%;" />
<h6 id="cnn-unpooling">CNN UnPooling</h6>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221014083346537.png" alt="image-20221014083346537" style="zoom:50%;" />
<h6 id="cnn-deconvolution">CNN Deconvolution</h6>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221014083956044.png" alt="image-20221014083956044" style="zoom:50%;" />
<blockquote>
<p>对输入进行扩充，然后放入到一个新的convolution里面，最后实现deconvolution</p>
</blockquote>
<h5 id="深度学习和流形">深度学习和流形</h5>
<p>流行的本质就是很多欧式空间粘贴在一起构成的空间</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221014091113179.png" alt="image-20221014091113179" style="zoom: 33%;" />
<p>深度学习的主要目的和功能之一就是学习编码映射和解码映射</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>将带噪声的图像进行傅里叶变换</p>
<ul class="lvl-2">
<li class="lvl-4">在频域滤波，去除高频分量</li>
</ul>
</li>
<li class="lvl-2">
<p>之后通过傅里叶的逆变换得到去噪之后的图片</p>
</li>
</ul>
<p>局限性</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>必须具有流行</p>
</li>
<li class="lvl-2">
<p>不同的类型需要不同的流行</p>
</li>
<li class="lvl-2">
<p>深度学习仍属于弱人工智能</p>
</li>
</ul>
<h3 id="textcolor-red-考-深度学习有效性的几何解释"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mtext>深度学习有效性的几何解释</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.深度学习有效性的几何解释}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">深度学习有效性的几何解释</span></span></span></span></h3>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221014093604606.png" alt="image-20221014093604606" style="zoom:50%;" />
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221014093617698.png" alt="image-20221014093617698" style="zoom:50%;" />
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221014093708338.png" alt="image-20221014093708338" style="zoom:50%;" />
<h6 id="胞腔分解和等价类">胞腔分解和等价类</h6>
<h3 id="textcolor-red-考-胞腔分解与等价类"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mtext>胞腔分解与等价类</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.胞腔分解与等价类}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">胞腔分解与等价类</span></span></span></span></h3>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>每一个胞腔对应于一个类</p>
</li>
<li class="lvl-2">
<p>所有彼此等价的点构成了背景空间中的一个胞腔</p>
</li>
<li class="lvl-2">
<p>编码映射诱导了胞腔的分解</p>
</li>
</ul>
</blockquote>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>来自ChatGPT</p>
</li>
</ul>
<p>胞腔分解和等价类是拓扑学中两个重要的概念，它们之间存在一定的关系。</p>
<p>胞腔分解是指将一个拓扑空间分解为一系列胞腔的并集，其中胞腔是指具有像拓扑结构的单元。胞腔分解是一种重要的拓扑空间描述方法，通常用于研究空间的拓扑性质。</p>
<p>等价类是指具有相同等价关系的元素组成的集合，其中等价关系是指满足自反性、对称性和传递性的关系。在拓扑学中，我们可以定义一个等价关系，使得空间中的点可以被分类为不同的等价类。这些等价类可以表示空间的拓扑结构，例如空间的连通性、同伦类型等。</p>
<p>在拓扑学中，一个空间的胞腔分解可以用于定义一个等价关系，使得空间中的点可以被分类为不同的等价类。具体来说，如果两个点可以通过一个或多个胞腔连通，则这些点被视为等价的。这种等价关系称为同伦等价，即这些点可以通过同伦变形相互转换，它们具有相同的同伦类型。</p>
<p>因此，胞腔分解和等价类是密切相关的，胞腔分解提供了一种描述空间拓扑结构的方法，而等价类则可以表示拓扑结构中的不同同伦类型。通过胞腔分解，我们可以研究空间的拓扑性质，并将其分类为不同的同伦类型。</p>
</blockquote>
<h3 id="textcolor-red-考-单词上下文互预测"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mtext>单词上下文互预测</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.单词上下文互预测}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">单词上下文互预测</span></span></span></span></h3>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221025164317392.png" alt="image-20221025164317392" style="zoom:50%;" />
<blockquote>
<p>考试题为此页PPT的内容</p>
</blockquote>
<h3 id="rnn">RNN</h3>
<p>循环神经网络（Recurrent Neural Network，RNN）是一种用于处理序列数据的神经网络。相比一般的神经网络来说，他能够处理序列变化的数据。比如某个单词的意思会因为上文提到的内容不同而有不同的含义，RNN就能够很好地解决这类问题。</p>
<h4 id="lstm">LSTM</h4>
<p>长短期记忆（Long short-term memory, LSTM）是一种特殊的RNN，主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现。</p>
<p>下图存在Input Gate（输入门）、Output Gate（输出门）、Forget Gate（遗忘门）：</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221021081347103.png" alt="image-20221021081347103" style="zoom:50%;" />
<blockquote>
<p>forget gate打开的时候代表的是记得，关闭的时候代表的是遗忘。</p>
<p>三个门均存在以下规则：</p>
<ul class="lvl-1">
<li class="lvl-2">
<p>当输入通过sigmod函数之后得到的值为0时，表明该门是关闭的；</p>
</li>
<li class="lvl-2">
<p>当输入通过sigmod函数之后得到的值为1时，表明该门是开启的；</p>
</li>
</ul>
</blockquote>
<h3 id="textcolor-red-考-lstm过程-门计算"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mi>L</mi><mi>S</mi><mi>T</mi><mi>M</mi><mtext>过程</mtext><mi mathvariant="normal">.</mi><mtext>门计算</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.LSTM过程.门计算}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord mathnormal" style="color:red;">L</span><span class="mord mathnormal" style="margin-right:0.10903em;color:red;">STM</span><span class="mord cjk_fallback" style="color:red;">过程</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">门计算</span></span></span></span></h3>
<blockquote>
<img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20221021082133328.png" alt="image-20221021082133328" style="zoom:50%;" />
<p>x1是输入</p>
<p>x2 = 1 ,输入<strong>将</strong>被写入memory</p>
<p>x2 = <mark>-1</mark> ,<strong>将</strong>置零memory</p>
<p>x3 = 1 ,<strong>立即</strong>输出memory</p>
<p><img src="https://ressmatthew-picture-cloud-storage.oss-cn-hangzhou.aliyuncs.com/img/image-20221021090718248.png" alt="image-20221021090718248"></p>
<blockquote>
<p>Forget gate门</p>
<ul class="lvl-2">
<li class="lvl-2">= 1,保留记忆</li>
<li class="lvl-2">= 0, 遗忘memory</li>
</ul>
</blockquote>
</blockquote>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221021083024030.png" alt="image-20221021083024030" style="zoom:50%;" />
<blockquote>
<p>需要掌握以上计算步骤。</p>
</blockquote>
<p>原始的神经元的输入和输出：</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221021090704835.png" alt="image-20221021090704835" style="zoom: 25%;" />
<p>将原来简单的neuron换成LSTM：</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221021090729363.png" alt="image-20221021090729363" style="zoom:33%;" />
<blockquote>
<p>LSTM需要的参数量(假设你现在用的neural的数目跟LSTM是一样的)是一般neural network的四倍。</p>
</blockquote>
<h6 id="lstm基本流程图：">LSTM基本流程图：</h6>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221021091934708.png" alt="image-20221021091934708" style="zoom:50%;" />
<h6 id="对lstm改进：">对LSTM改进：</h6>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221021091913677.png" alt="image-20221021091913677" style="zoom:50%;" />
<ul class="lvl-0">
<li class="lvl-2">
<p>x<sup>t</sup>是当前状态</p>
</li>
</ul>
<blockquote>
<p>参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32085405">人人都能看懂的LSTM - 知乎 (zhihu.com)</a></p>
</blockquote>
<h4 id="怎么学rnn">怎么学RNN</h4>
<p>问题：为什么RNN会有这种奇特的特性。有人会说，是不是来自sigmoid function，我们之前讲过Relu activation function的时候，讲过一个问题gradient vanish，这个问题是从sigmoid function来的，RNN会有很平滑的error surface是因为来自于gradient vanish，这问题我是不认同的。等一下来看这个问题是来自sigmoid function，你换成Relu去解决这个问题就不是这个问题了。跟大家讲个秘密，一般在train neural network时，一般很少用Relu来当做activation function。为什么呢？其实你把sigmoid function换成Relu，其实在RNN performance通常是比较差的。所以activation function并不是这里的关键点。</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221021093445621.png" alt="image-20221021093445621" style="zoom:33%;" />
<p>RNN training的问题其实来自它把同样的东西在transition的时候反复使用。所以这个w只要一有变化，它完全由可能没有造成任何影响，一旦造成影响，影响都是天崩地裂的(所以gradient会很大，gradient会很小)。</p>
<blockquote>
<p>单个样本可能会发生梯度消失的问题。</p>
</blockquote>
<h3 id="textcolor-red-考-为什么lstm能够解决梯度消失的问题"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mtext>为什么</mtext><mi>L</mi><mi>S</mi><mi>T</mi><mi>M</mi><mtext>能够解决梯度消失的问题</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.为什么LSTM能够解决梯度消失的问题}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">为什么</span><span class="mord mathnormal" style="color:red;">L</span><span class="mord mathnormal" style="margin-right:0.10903em;color:red;">STM</span><span class="mord cjk_fallback" style="color:red;">能够解决梯度消失的问题</span></span></span></span></h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>memory和输入时相加的</p>
</li>
<li class="lvl-2">
<p>这种累加效果一直存在，直到遗忘门关闭才会消失</p>
</li>
</ul>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>来自ChatGPT</p>
</li>
</ul>
<p>LSTM（Long Short-Term Memory）是一种常用的循环神经网络（RNN）结构，相对于传统的 RNN，LSTM 可以更好地解决梯度消失的问题。LSTM 之所以能够解决梯度消失的问题，主要有以下两个原因：</p>
<ol>
<li class="lvl-3">
<p>长期记忆机制：传统的 RNN 中，当网络层数很多时，由于在反向传播时每一层的梯度会相乘，因此当梯度较小时，多层网络的梯度会变得非常小，从而导致梯度消失。而 LSTM 通过引入长期记忆机制，可以更好地处理长期依赖性，从而避免梯度消失问题的发生。在 LSTM 中，通过门控单元的机制，可以控制信息的流动和保留，从而能够更好地处理长序列数据。</p>
</li>
<li class="lvl-3">
<p>反向传播中的梯度削减：另一个原因是 LSTM 的反向传播过程中，对梯度的处理方式有所改进。在 LSTM 的反向传播中，使用了一个特殊的误差反向传播算法（Backpropagation through time, BPTT），它可以在一定程度上避免梯度爆炸。当梯度过大时，LSTM 会通过削减梯度的方式，使梯度的范数不超过一个预设的值。这个预设的值可以通过裁剪梯度（gradient clipping）的方式来实现，从而避免梯度爆炸的问题。</p>
</li>
</ol>
<p>综上所述，LSTM 通过引入长期记忆机制和反向传播中的梯度削减，可以更好地解决梯度消失和梯度爆炸的问题，从而能够更好地处理长序列数据。</p>
</blockquote>
<p>首先将原始数据通过CNN或RNN提取出重要特征之后再放入到以下图中：</p>
<p><img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221025162922359.png" alt="image-20221025162922359"></p>
<h3 id="图片搜索和语言搜索">图片搜索和语言搜索</h3>
<p>图片搜索类似图片是用CNN</p>
<blockquote>
<p>图片搜索使用CNN提取特征</p>
<p>语音搜索使用RNN提取向量</p>
</blockquote>
<h3 id="textcolor-red-考-图片搜索和语言搜索提取比较"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mtext>图片搜索和语言搜索提取比较</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.图片搜索和语言搜索提取比较}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">图片搜索和语言搜索提取比较</span></span></span></span></h3>
<blockquote>
<p>主图片<strong>CNN</strong>提取<strong>特征</strong></p>
<p>从图片CNN提取特征</p>
<p>比较</p>
</blockquote>
<blockquote>
<p>主语音<strong>RNN</strong>提取<strong>向量</strong></p>
<p>从语音RNN提取向量</p>
<p>比较</p>
</blockquote>
<p>基于注意力的模型（Attension-based Model）</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221025170837297.png" alt="image-20221025170837297" style="zoom:50%;" />
<p>最简易的基于注意力的模型V1</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221025171009500.png" alt="image-20221025171009500" style="zoom:50%;" />
<p>基于注意力的模型V2</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221025171033162.png" alt="image-20221025171033162" style="zoom:50%;" />
<p>machine阅读理解</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221025171654756.png" alt="image-20221025171654756" style="zoom:50%;" />
<h4 id="rnn-structured-learning">RNN &amp; Structured learning</h4>
<h3 id="深度学习的攻防">深度学习的攻防</h3>
<h5 id="motivation">Motivation</h5>
<ul class="lvl-0">
<li class="lvl-2">
<p>期望机器学习的分类器对恶意的或非恶意的错误input具有一定的鲁棒性</p>
</li>
<li class="lvl-2">
<p>恶意软件检测以及网络入侵检测（spam malware intrusion detection）</p>
</li>
</ul>
<h5 id="noise像素点attack">noise像素点attack</h5>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221028083946316.png" alt="image-20221028083946316" style="zoom:50%;" />
<h3 id="textcolor-red-考-无目标攻击和目标攻击公式"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mtext>考</mtext><mi mathvariant="normal">.</mi><mtext>无目标攻击和目标攻击公式</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{考.无目标攻击和目标攻击公式}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback" style="color:red;">考</span><span class="mord" style="color:red;">.</span><span class="mord cjk_fallback" style="color:red;">无目标攻击和目标攻击公式</span></span></span></span></h3>
<blockquote>
<p>Non-target Attack：公式如上图所示</p>
<p>Targeted Attack：公式如上图所示</p>
</blockquote>
<h5 id="constraint">Constraint</h5>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221028085925008.png" alt="image-20221028085925008" style="zoom:50%;" />
<h5 id="attack的实现方式">Attack的实现方式</h5>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221028092228643.png" alt="image-20221028092228643" style="zoom:50%;" />
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221028092155726.png" alt="image-20221028092155726" style="zoom:50%;" />
<h5 id="attack-approaches">Attack Approaches</h5>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221028092832191.png" alt="image-20221028092832191" style="zoom:50%;" />
<h5 id="white-box与black-box">White Box与Black Box</h5>
<blockquote>
<p>白盒攻击：在知道模型的情况下对模型进行攻击（此时清楚算法的参数、结构等）</p>
<p>黑盒攻击：在不知道模型的情况下对模型进行攻击（此时不知道任何模型的结构或是参数）</p>
</blockquote>
<h4 id="黑盒攻击">黑盒攻击</h4>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221101162010977.png" alt="image-20221101162010977" style="zoom: 50%;" />
<blockquote>
<p>通过寻找图片样本输入到待攻击模型中训练之后得到结果，将训练的样本和结果用来训练自己的模型，这个时候可以训练出功能与待攻击模型相似的可知具体模型结构的自建模型，此时能够对自建模型进行attack的对抗样本也很有可能对待攻击模型产生相同的攻击效果。</p>
</blockquote>
<p>通过待攻击模型得到的结果来训练自己模型的详细过程：</p>
<p><img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221101165240517.png" alt="image-20221101165240517"></p>
<h3 id="defense">Defense</h3>
<p>Two types：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>被动防御（passive defense）</p>
<ul class="lvl-2">
<li class="lvl-4">方式一：加入一个过滤器（Filter）
<ul class="lvl-4">
<li class="lvl-6">
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221101172424920.png" alt="image-20221101172424920" style="zoom:50%;" />
</li>
</ul>
</li>
<li class="lvl-4">方式二：判断max(d1,d2)&gt;T</li>
<li class="lvl-4">方式三：resizing layer in CNN
<ul class="lvl-4">
<li class="lvl-6">原始图片在resizing过程中的稳定性好</li>
<li class="lvl-6">对抗样本在resizing过程中的稳定差</li>
</ul>
</li>
</ul>
</li>
<li class="lvl-2">
<p>主动防御（proactive defense）</p>
<ul class="lvl-2">
<li class="lvl-4">
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221101173503967.png" alt="image-20221101173503967" style="zoom:50%;" />
</li>
</ul>
</li>
</ul>
<h2 id="meta-learning">Meta Learning</h2>
<p>Meta Learning=learn to learn</p>
<p>Machine Learning：寻找函数f的能力</p>
<p>Meta Learning：寻找函数f的函数F的能力</p>
<h4 id="textcolor-red-12周上实验课"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathcolor="red"><mn>12</mn><mtext>周上实验课</mtext></mstyle></mrow><annotation encoding="application/x-tex">\textcolor{red}{12周上实验课}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord" style="color:red;">12</span><span class="mord cjk_fallback" style="color:red;">周上实验课</span></span></span></span></h4>
<h3 id="meta-learning流程">Meta Learning流程</h3>
<p>确定函数F（建立模型）</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221104081912906.png" alt="image-20221104081912906" style="zoom:50%;" />
<blockquote>
<p>最后返回的函数f是一个结构（网络结构）。</p>
<p>F&lt;NS,Init,Update&gt;</p>
<ul class="lvl-1">
<li class="lvl-2">
<p>NS：Network Structure</p>
</li>
<li class="lvl-2">
<p>Init：初始化</p>
</li>
<li class="lvl-2">
<p>Update：更新</p>
</li>
</ul>
</blockquote>
<p>定义函数F的好坏</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221104083014964.png" alt="image-20221104083014964" style="zoom: 67%;" />
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221104083512570.png" alt="image-20221104083512570" style="zoom:50%;" />
<p>定义损失函数F，并找到最好的损失函数</p>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221104083452206.png" alt="image-20221104083452206" style="zoom:50%;" />
<h4 id="maml">MAML</h4>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221104090226044.png" alt="image-20221104090226044" style="zoom:50%;" />
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221104091213991.png" alt="image-20221104091213991" style="zoom:50%;" />
<h4 id="model-pre-training">Model Pre-training</h4>
<blockquote>
<p>先有大数据训练集训练得到NS，之后再将NS作为参数并使用小数据量的数据集进一步调整NS</p>
</blockquote>
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221104091857201.png" alt="image-20221104091857201" style="zoom:50%;" />
<img src="https://wangguijie-typora.oss-cn-chengdu.aliyuncs.com/img/image-20221104093925342.png" alt="image-20221104093925342" style="zoom:50%;" />
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://wangguijiepedeval.github.io/2023/05/11/University/junior/course/Scientific%20Computing%20and%20Mathematical%20Modeling/%E5%BC%80%E5%8D%B7%E5%AE%9D%E5%85%B8plus+/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/" rel="tag">期末复习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" rel="tag">科学计算与数学建模</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2023/05/11/University/junior/course/Scientific%20Computing%20and%20Mathematical%20Modeling/keras%E4%BB%A3%E7%A0%81%E5%9F%BA%E7%A1%80/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            keras基础
          
        </div>
      </a>
    
    
      <a href="/2023/05/11/University/junior/course/electronic_commerce/2022%E7%94%B5%E5%AD%90%E5%95%86%E5%8A%A1%E5%BA%94%E7%94%A8%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">2022年期末考试复习总结</div>
      </a>
    
  </nav>

  
   
<div class="gitalk" id="gitalk-container"></div>

<link rel="stylesheet" href="https://cdn.staticfile.org/gitalk/1.7.2/gitalk.min.css">


<script src="https://cdn.staticfile.org/gitalk/1.7.2/gitalk.min.js"></script>


<script src="https://cdn.staticfile.org/blueimp-md5/2.19.0/js/md5.min.js"></script>

<script type="text/javascript">
  var gitalk = new Gitalk({
    clientID: 'ab8e83b45b1c73553e5a',
    clientSecret: 'c34256673ed529723bdea8d206ac6cb5c12e57bb',
    repo: 'wgj_blog_talk',
    owner: 'wangguijiepedeval',
    admin: ['wangguijiepedeval'],
    // id: location.pathname,      // Ensure uniqueness and length less than 50
    id: md5(location.pathname),
    distractionFreeMode: false,  // Facebook-like distraction free mode
    pagerDirection: 'last'
  })

  gitalk.render('gitalk-container')
</script>

  
   
    <script src="https://cdn.staticfile.org/twikoo/1.4.18/twikoo.all.min.js"></script>
    <div id="twikoo" class="twikoo"></div>
    <script>
        twikoo.init({
            envId: ""
        })
    </script>
 
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2023
        <i class="ri-heart-fill heart_icon"></i> Guijie Wang
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Wgj&#39;s blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">旅行</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" target="_blank" rel="noopener" href="https://hexo.io/themes/">主题</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/player">播放器</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->
 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.staticfile.org/mathjax/2.7.7/MathJax.js"></script>
<script src="https://cdn.staticfile.org/mathjax/2.7.7/config/TeX-AMS-MML_HTMLorMML-full.js"></script>
<script>
  var ayerConfig = {
    mathjax: true,
  };
</script>

<!-- Katex -->
 
    
        <link rel="stylesheet" href="https://cdn.staticfile.org/KaTeX/0.15.1/katex.min.css">
        <script src="https://cdn.staticfile.org/KaTeX/0.15.1/katex.min.js"></script>
        <script src="https://cdn.staticfile.org/KaTeX/0.15.1/contrib/auto-render.min.js"></script>
        
    
 
<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<script src="https://cdn.staticfile.org/animejs/3.2.1/anime.min.js"></script>

<script src="/js/clickBoom1.js"></script>
 
<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->
 
<script src="/js/dz.js"></script>
 
<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>